{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e4eb7534",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "import json\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm.auto import tqdm\n",
    "import shutil\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2f4a3b6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "be2f8e76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['classes.json',\n",
       " 'classes_with_dont_care.json',\n",
       " 'labels',\n",
       " 'labels_with_dont_care',\n",
       " 'testing',\n",
       " 'training']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_dir = Path(\"data\")\n",
    "import os\n",
    "os.listdir(base_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d8be1fec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(WindowsPath('data/labels'), WindowsPath('data/training/image_2'))"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_path= base_dir / 'training' / 'image_2'\n",
    "label_path =base_dir / 'labels'\n",
    "label_path,img_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a624fc19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Car': 0,\n",
       " 'Pedestrian': 1,\n",
       " 'Van': 2,\n",
       " 'Cyclist': 3,\n",
       " 'Truck': 4,\n",
       " 'Misc': 5,\n",
       " 'Tram': 6,\n",
       " 'Person_sitting': 7}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(base_dir/'classes.json',\"r\") as f:\n",
    "    classes=json.load(f)\n",
    "    \n",
    "classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "577a245e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(WindowsPath('data/training/image_2/000000.png'),\n",
       "  WindowsPath('data/labels/000000.txt')),\n",
       " (WindowsPath('data/training/image_2/000001.png'),\n",
       "  WindowsPath('data/labels/000001.txt')),\n",
       " (WindowsPath('data/training/image_2/000002.png'),\n",
       "  WindowsPath('data/labels/000002.txt'))]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images = list(img_path.glob(\"*.png\"))\n",
    "labels = list(label_path.glob(\"*.txt\"))\n",
    "pairs=list(zip(images, labels))\n",
    "pairs[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "579e45c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6732, 749)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_pairs, val_pairs = train_test_split(pairs, test_size=0.1, random_state=42)\n",
    "len(train_pairs), len(val_pairs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbfa0c07",
   "metadata": {},
   "source": [
    "# Convert Seperate Vehicle Detection Dataset to YOLO Format\n",
    "```\n",
    "/kaggle/working\n",
    "    |\n",
    "    -train\n",
    "    |   |\n",
    "    |   -000000.png\n",
    "    |   -000000.txt\n",
    "    |   ...\n",
    "    |\n",
    "    -val\n",
    "      |\n",
    "      -000001.png\n",
    "      -000001.txt\n",
    "      ...\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8f5b0bfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = Path('train').resolve()\n",
    "train_path.mkdir(exist_ok=True)\n",
    "valid_path = Path('valid').resolve()\n",
    "valid_path.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "61147b07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "118ae4f940ff46918ae2545aaf7c241b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6732 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for t_img, t_lb in tqdm(train_pairs):\n",
    "    im_path = train_path / t_img.name\n",
    "    lb_path = train_path / t_lb.name\n",
    "    shutil.copy(t_img,im_path)\n",
    "    shutil.copy(t_lb,lb_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c204c9a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "80d7748e703f475f88ed1d0afd4d012b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/749 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for t_img, t_lb in tqdm(val_pairs):\n",
    "    im_path = valid_path / t_img.name\n",
    "    lb_path = valid_path / t_lb.name\n",
    "    shutil.copy(t_img,im_path)\n",
    "    shutil.copy(t_lb,lb_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d9eb9b5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "yaml_content = f\"\"\"\n",
    "names:\n",
    "- Car\n",
    "- Pedestrian\n",
    "- Van\n",
    "- Cyclist\n",
    "- Truck\n",
    "- Misc\n",
    "- Tram\n",
    "- Person_sitting\n",
    "nc: 8\n",
    "train: train\n",
    "val: valid\n",
    "\"\"\"\n",
    "with open('data.yaml', 'w') as f:\n",
    "    f.write(yaml_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "7e97b1b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[KDownloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolov8n.pt to 'yolov8n.pt': 100% ━━━━━━━━━━━━ 6.2MB 5.9MB/s 1.1s.0s<0.2s2.1s8s\n"
     ]
    }
   ],
   "source": [
    "model = YOLO('yolov8n.yaml')\n",
    "model = YOLO('yolov8n.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8013a0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !yolo train model=/kaggle/working/yolo12s.pt  \\\n",
    "#     data=\"/kaggle/input/kitti-dataset-yolo-format/Kitti Dataset Yolo Format/data.yaml\" \\\n",
    "#     epochs=50 batch=32 \\\n",
    "#     degrees=15 translate=0.1 scale=0.5 shear=5 perspective=0.0005 \\\n",
    "#     flipud=0.2 fliplr=0.5 hsv_h=0.015 hsv_s=0.7 hsv_v=0.4 \\\n",
    "#     mosaic=1.0 mixup=0.2 copy_paste=0.2 workers=4 device=0 \\\n",
    "#     project=/kaggle/working/output \\\n",
    "#     name=trained_model \\\n",
    "#     save=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "615258c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the trained model\n",
    "trained_model = YOLO('/kaggle/working/output/trained_model/weights/best.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75e45055",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make prediction on a sample image\n",
    "sample_image_path = '/kaggle/input/kitti-dataset-yolo-format/Kitti Dataset Yolo Format/images/test_image.jpg'  # Replace with your image path\n",
    "\n",
    "results = trained_model.predict(source=sample_image_path, conf=0.5)\n",
    "\n",
    "# Display results\n",
    "for result in results:\n",
    "    print(f\"Detections found: {len(result.boxes)}\")\n",
    "    print(f\"Classes: {result.names}\")\n",
    "    print(f\"Confidence scores: {result.boxes.conf}\")\n",
    "    print(f\"Bounding boxes: {result.boxes.xyxy}\")\n",
    "    \n",
    "    # Display image with predictions\n",
    "    result.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed7d22d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alternative: Batch prediction on multiple images\n",
    "from pathlib import Path\n",
    "\n",
    "image_folder = '/kaggle/input/kitti-dataset-yolo-format/Kitti Dataset Yolo Format/images/test/'\n",
    "image_files = list(Path(image_folder).glob('*.jpg'))\n",
    "\n",
    "# Predict on all images\n",
    "batch_results = trained_model.predict(source=image_files, conf=0.5)\n",
    "\n",
    "# Process results\n",
    "for i, result in enumerate(batch_results):\n",
    "    print(f\"\\nImage {i+1}: {result.path}\")\n",
    "    print(f\"Detections: {len(result.boxes)}\")\n",
    "    for j, box in enumerate(result.boxes):\n",
    "        class_id = int(box.cls[0])\n",
    "        confidence = float(box.conf[0])\n",
    "        class_name = result.names[class_id]\n",
    "        print(f\"  Object {j+1}: {class_name} (confidence: {confidence:.2f})\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
