{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "807858ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "from glob import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8470efdf",
   "metadata": {},
   "source": [
    "Step 1 - Load Cornell files and build QA pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "49d268e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "lines_file = Path(r\"E:\\70 Days 70 Project\\Chatbot with Seq2Seq Model\\cornell movie-dialogs corpus\\movie_lines.txt\")\n",
    "convs_file = Path(r\"E:\\70 Days 70 Project\\Chatbot with Seq2Seq Model\\cornell movie-dialogs corpus\\movie_conversations.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5df7b360",
   "metadata": {},
   "outputs": [],
   "source": [
    "MIN_LEN=1\n",
    "MAX_LEN=20\n",
    "\n",
    "\"\"\"\n",
    "movie_lines.txt format (roughly):\n",
    "lineID +++$+++ characterID +++$+++ movieID +++$+++ characterName +++$+++ text\n",
    " 0                  1                 2                 3                 4\n",
    "\"\"\"\n",
    "\n",
    "def load_lines(lines_file):\n",
    "    id2line = {}\n",
    "    with open(lines_file, 'r', encoding='iso-8859-1') as f:\n",
    "        for line in f:\n",
    "            parts = line.strip().split(\" +++$+++ \")\n",
    "            if len(parts) == 5:\n",
    "                line_id = parts[0] # ID of the line\n",
    "                text = parts[4] # Text of the line\n",
    "                id2line[line_id] = text\n",
    "    #PRINT SAMPLE LINES\n",
    "    sample_keys = list(id2line.keys())[:3]\n",
    "    print(\"Sample lines:\")\n",
    "    for k in sample_keys:\n",
    "        print(\" \", k, \"->\", id2line[k])\n",
    "    return id2line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a26a2e30",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "movie_conversations.txt format:\n",
    "character1ID +++$+++ character2ID +++$+++ movieID +++$+++ utteranceIDs\n",
    "utteranceIDs is like:\n",
    "    ['L194', 'L195', 'L196', ...]\n",
    "\"\"\"\n",
    "import re\n",
    "\n",
    "def load_conversations(convs_file):\n",
    "    conversations=[]\n",
    "    with open(convs_file, 'r', encoding='iso-8859-1') as f:\n",
    "        for line in f:\n",
    "            parts = line.strip().split(\" +++$+++ \")\n",
    "            if len(parts) == 4:\n",
    "                line_ids_str = parts[3] # This is a string like \"['L194', 'L195', ...]\"\n",
    "                line_ids = re.findall(r\"L\\d+\", line_ids_str)  # extract all line IDs like L1234\n",
    "                if len(line_ids) >= 2:\n",
    "                    conversations.append(line_ids)\n",
    "    print(\"Sample conversation lineIDs:\", conversations[0:3])\n",
    "    return conversations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "af29fbd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample lines:\n",
      "  L1045 -> They do not!\n",
      "  L1044 -> They do to!\n",
      "  L985 -> I hope so.\n",
      "Sample conversation lineIDs: [['L194', 'L195', 'L196', 'L197'], ['L198', 'L199'], ['L200', 'L201', 'L202', 'L203']]\n"
     ]
    }
   ],
   "source": [
    "id2line=load_lines(lines_file)\n",
    "all_conversations_list=load_conversations(convs_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2ed7d2a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_pairs(all_conversations_list,id2line):\n",
    "    pairs=[]\n",
    "    for conv in all_conversations_list:\n",
    "        for i in range(len(conv)-1):\n",
    "            dialog_1_id=conv[i]\n",
    "            dialog_2_id=conv[i+1]\n",
    "            \n",
    "            dialog_1_text=id2line.get(dialog_1_id,\"\").strip()\n",
    "            dialog_2_text=id2line.get(dialog_2_id,\"\").strip()\n",
    "            \n",
    "            if dialog_1_text and dialog_2_text:\n",
    "                pairs.append((dialog_1_text,dialog_2_text))\n",
    "                \n",
    "    print(\" Speaker A:\", pairs[0][0])\n",
    "    print(\" Speaker B:\", pairs[0][1])\n",
    "    return pairs\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ce281e45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Speaker A: Can we make this quick?  Roxanne Korrine and Andrew Barrett are having an incredibly horrendous public break- up on the quad.  Again.\n",
      " Speaker B: Well, I thought we'd start with pronunciation, if that's okay with you.\n"
     ]
    }
   ],
   "source": [
    "all_pairs=build_pairs(all_conversations_list,id2line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0d8d86f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_text(s):\n",
    "    s = s.lower().strip()\n",
    "    # separate punctuation slightly: \"hi!\" -> \"hi !\"\n",
    "    s = re.sub(r\"([.!?])\", r\" \\1\", s)\n",
    "    # remove weird characters (keep a-z, punctuation)\n",
    "    s = re.sub(r\"[^a-z.!?]+\", \" \", s)\n",
    "    # remove extra spaces\n",
    "    s = re.sub(r\"\\s+\", \" \", s).strip()\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "86e919df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_pairs(pairs, min_len=MIN_LEN, max_len=MAX_LEN):\n",
    "    filtered = []\n",
    "    for q, a in pairs:\n",
    "        qn = normalize_text(q)\n",
    "        an = normalize_text(a)\n",
    "\n",
    "        q_len = len(qn.split())\n",
    "        a_len = len(an.split())\n",
    "\n",
    "        if min_len <= q_len <= max_len and min_len <= a_len <= max_len:\n",
    "            filtered.append((qn, an))\n",
    "    print(\"Sample cleaned pair:\")\n",
    "    print(\" Q:\", filtered[0][0])\n",
    "    print(\" A:\", filtered[0][1])\n",
    "    return filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ff8b451e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample cleaned pair:\n",
      " Q: well i thought we d start with pronunciation if that s okay with you .\n",
      " A: not the hacking and gagging and spitting part . please .\n"
     ]
    }
   ],
   "source": [
    "filter_pairs=filter_pairs(all_pairs, MIN_LEN, MAX_LEN)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ea282f2",
   "metadata": {},
   "source": [
    "Build Vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "dac8834d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Vocabulary:\n",
    "    def __init__(self):\n",
    "        # Special tokens with reserved indices\n",
    "        self.PAD_token = 0\n",
    "        self.SOS_token = 1\n",
    "        self.EOS_token = 2\n",
    "        self.UNK_token = 3\n",
    "\n",
    "        # Initialize mappings with special tokens \n",
    "        self.word2index = {\n",
    "            \"<PAD>\": self.PAD_token,\n",
    "            \"<SOS>\": self.SOS_token,\n",
    "            \"<EOS>\": self.EOS_token,\n",
    "            \"<UNK>\": self.UNK_token\n",
    "        }\n",
    "\n",
    "        self.index2word = {\n",
    "            self.PAD_token: \"<PAD>\",\n",
    "            self.SOS_token: \"<SOS>\",\n",
    "            self.EOS_token: \"<EOS>\",\n",
    "            self.UNK_token: \"<UNK>\"\n",
    "        }\n",
    "\n",
    "        self.word2count = {}\n",
    "\n",
    "        self.next_num = 4  # position for next new word (as special tokens are 0-3)\n",
    "\n",
    "    def add_sentence(self, sentence):\n",
    "\n",
    "        for word in sentence.split():\n",
    "            self.add_word(word)\n",
    "\n",
    "    # this function adds a word to the vocabulary based on whether it's new or existing\n",
    "    def add_word(self, word):\n",
    "        if word not in self.word2index:\n",
    "            # new word\n",
    "            self.word2index[word] = self.next_num\n",
    "            self.index2word[self.next_num] = word\n",
    "            self.word2count[word] = 1 # word counter\n",
    "            self.next_num += 1 # increment for next new word\n",
    "        else:\n",
    "            # existing word\n",
    "            self.word2count[word] += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "35e211ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total words in vocab: 33922\n",
      "<PAD> -> 0\n",
      "<SOS> -> 1\n",
      "<EOS> -> 2\n",
      "<UNK> -> 3\n",
      "well -> 4\n",
      "i -> 5\n",
      "thought -> 6\n",
      "we -> 7\n",
      "d -> 8\n",
      "start -> 9\n"
     ]
    }
   ],
   "source": [
    "# Build vocabulary\n",
    "vocab = Vocabulary()\n",
    "\n",
    "for q, a in filter_pairs:\n",
    "    vocab.add_sentence(q)\n",
    "    vocab.add_sentence(a)\n",
    "    \n",
    "print(\"Total words in vocab:\", vocab.next_num) # as next_num indicates total words\n",
    "\n",
    "# show some examples\n",
    "for word in list(vocab.word2index.keys())[:10]:\n",
    "    print(word, \"->\", vocab.word2index[word])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5fef5bfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentence_to_indices(vocab, sentence):\n",
    "    indices = [vocab.SOS_token]  # start with SOS\n",
    "    for word in sentence.split():\n",
    "        if word in vocab.word2index: \n",
    "            indices.append(vocab.word2index[word])\n",
    "        else:\n",
    "            indices.append(vocab.UNK_token)  # unknown word\n",
    "    indices.append(vocab.EOS_token)  # end with EOS\n",
    "    return indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "6f9810e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11101, 66)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab.word2count[\"can\"], vocab.word2index[\"can\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "46b405d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence: well i thought we d start with pronunciation if that s okay with you .\n",
      "Indexes: [1, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 10, 16, 17, 2]\n",
      "Back to words:\n",
      "['<SOS>', 'well', 'i', 'thought', 'we', 'd', 'start', 'with', 'pronunciation', 'if', 'that', 's', 'okay', 'with', 'you', '.', '<EOS>']\n"
     ]
    }
   ],
   "source": [
    "test_sentence = filter_pairs[0][0]\n",
    "print(\"Sentence:\", test_sentence)\n",
    "\n",
    "idxs = sentence_to_indices(vocab, test_sentence)\n",
    "print(\"Indexes:\", idxs)\n",
    "\n",
    "print(\"Back to words:\")\n",
    "print([vocab.index2word[i] for i in idxs])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa0714f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "def pad_sequence(seq, max_len):\n",
    "    # Convert tensor to list if needed\n",
    "    if isinstance(seq, torch.Tensor):\n",
    "        seq = seq.tolist()\n",
    "    return seq + [vocab.PAD_token] * (max_len - len(seq))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "46541656",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before padding:\n",
      "[1, 133, 17, 2]\n",
      "[1, 27, 286, 16, 35, 2]\n",
      "\n",
      "After padding:\n",
      "[1, 133, 17, 2, 0, 0]\n",
      "[1, 27, 286, 16, 35, 2]\n"
     ]
    }
   ],
   "source": [
    "seq1 = sentence_to_indices(vocab, \"hi .\")\n",
    "seq2 = sentence_to_indices(vocab, \"how are you ?\")\n",
    "\n",
    "max_len = max(len(seq1), len(seq2))\n",
    "\n",
    "print(\"Before padding:\")\n",
    "print(seq1)\n",
    "print(seq2)\n",
    "\n",
    "print(\"\\nAfter padding:\")\n",
    "print(pad_sequence(seq1, max_len))\n",
    "print(pad_sequence(seq2, max_len))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "b2f63c9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "\n",
    "class ChatDataset(Dataset):\n",
    "    def __init__(self, pairs, vocab):\n",
    "        self.pairs = pairs\n",
    "        self.vocab = vocab\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.pairs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        q, a = self.pairs[idx]\n",
    "        q_idxs = sentence_to_indices(self.vocab, q)\n",
    "        a_idxs = sentence_to_indices(self.vocab, a)\n",
    "        return torch.tensor(q_idxs, dtype=torch.long), torch.tensor(a_idxs, dtype=torch.long)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "92129dc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "    # sort by input length (important for LSTM)\n",
    "    \n",
    "    # This ensures pack_padded_sequence receives sequences in the correct order\n",
    "    batch.sort(key=lambda x: len(x[0]), reverse=True) # longest to shortest descending required by pack_padded_sequence\n",
    "\n",
    "    input_seqs, target_seqs = zip(*batch)\n",
    "\n",
    "    # codes to find the list of length of all seq and the max from it\n",
    "    input_lengths = [len(seq) for seq in input_seqs]\n",
    "    target_lengths = [len(seq) for seq in target_seqs]\n",
    "\n",
    "    max_input_len = max(input_lengths)\n",
    "    max_target_len = max(target_lengths)\n",
    "\n",
    "    # new input for appending padded sequence\n",
    "    padded_inputs = []\n",
    "    padded_targets = []\n",
    "\n",
    "    for inp, tgt in zip(input_seqs, target_seqs):\n",
    "        padded_inputs.append(pad_sequence(inp, max_input_len))\n",
    "        padded_targets.append(pad_sequence(tgt, max_target_len))\n",
    "\n",
    "    # convert to tensors\n",
    "    input_tensor = torch.tensor(padded_inputs, dtype=torch.long)\n",
    "    target_tensor = torch.tensor(padded_targets, dtype=torch.long)\n",
    "\n",
    "    return input_tensor, target_tensor, input_lengths, target_lengths\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "ddf7b035",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "\n",
    "dataset = ChatDataset(filter_pairs, vocab)\n",
    "\n",
    "dataloader = DataLoader(dataset,batch_size=BATCH_SIZE,shuffle=True,collate_fn=collate_fn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "e17c83e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[    1, 15701,    14,  1252,    17,    17,  2697,   155,   217,   132,\n",
       "            178,    47,   240,  4556,    17,    17,    17,     2],\n",
       "         [    1,   459,  7223,    21,  6504, 18984,   603,   500,   158,   190,\n",
       "            459,  2198,  3227,    17,    17,    17,     2,     0],\n",
       "         [    1,   400,    39,   149,    13,   372,  1509,    17,     5,   235,\n",
       "            620,    47,   175,    17,     2,     0,     0,     0],\n",
       "         [    1,     5,   255,   101,   256,   101,   132,    17,   206,    16,\n",
       "           3676,    17,    17,    17,     2,     0,     0,     0],\n",
       "         [    1,   296,   721,  3417, 15289,   296,   721,     7,    60,   112,\n",
       "            591,   185,  7426,    17,     2,     0,     0,     0],\n",
       "         [    1,   260,   424,     5,   125,    40,  3500,    17,     5,   125,\n",
       "           1438,   312,    17,     2,     0,     0,     0,     0],\n",
       "         [    1,    64,    14,   580,    83,  2214,   127,    19,  2976,  6816,\n",
       "             17,     2,     0,     0,     0,     0,     0,     0],\n",
       "         [    1,   286,    16,  1270,    35,   157,   198,  1472,    16,    35,\n",
       "              2,     0,     0,     0,     0,     0,     0,     0],\n",
       "         [    1,   120,  1609,    17,   471,    39,   615,    16,   255,    17,\n",
       "              2,     0,     0,     0,     0,     0,     0,     0],\n",
       "         [    1,    19,  2035,   348,    89,   903,    77,   674,   178,     2,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0],\n",
       "         [    1,    73,    72,    31,  1251,   190,    54,  4026,    35,     2,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0],\n",
       "         [    1,     4,   128,    14,    18,   984,   182,   132,    17,     2,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0],\n",
       "         [    1,     5,   214,    52,   139,    42,    13,   265,    17,     2,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0],\n",
       "         [    1,   202,     5,    51,    52,    99,   165,    17,     2,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0],\n",
       "         [    1,    72,    73,  2168,    17, 23820,  4242,    17,     2,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0],\n",
       "         [    1,    26,    17,    17,    17,    42,    35,     2,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0],\n",
       "         [    1,    42,    14,   459,   680,    44,    35,     2,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0],\n",
       "         [    1,   979,    68,   399,    17,    17,    17,     2,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0],\n",
       "         [    1,   211,    42,    35,   211,    42,    35,     2,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0],\n",
       "         [    1,    66,    16,  2287,    13,   228,    17,     2,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0],\n",
       "         [    1,     5,  3737,   180,   293,    16,    17,     2,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0],\n",
       "         [    1,    42,   182,  9418, 32453,    35,     2,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0],\n",
       "         [    1,   385,   127,  2995,    17,     2,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0],\n",
       "         [    1,    40,    67,     5,    17,     2,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0],\n",
       "         [    1,   128,    73, 25572,    17,     2,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0],\n",
       "         [    1,    16,    15,  4189,    35,     2,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0],\n",
       "         [    1,     5,   235,    67,    47,     2,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0],\n",
       "         [    1,  2770,   312,    35,     2,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0],\n",
       "         [    1,   260,   133,   178,     2,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0],\n",
       "         [    1,   408,    17,     2,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0],\n",
       "         [    1, 27454,   178,     2,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0],\n",
       "         [    1,    15,    17,     2,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0]]),\n",
       " tensor([[    1,   260,   528,    13,    14,   201,   205,    17,    17,    17,\n",
       "              2,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0],\n",
       "         [    1,    40,    16,    37,  1164,   200,   454,   785,    19,  2929,\n",
       "           1831,    75,    21,   671,    17,     2,     0,     0,     0,     0,\n",
       "              0,     0],\n",
       "         [    1,    42,  1038,     5,   167,   620,    35,     2,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0],\n",
       "         [    1,   260,    16,    37,   459,  1230,   534,    17,    17,    17,\n",
       "             35,     2,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0],\n",
       "         [    1,     5,    59,  8205,    10,    49,   271,   110,    49,   555,\n",
       "             17,     2,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0],\n",
       "         [    1,   202,    17,     2,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0],\n",
       "         [    1,   819,    17,     2,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0],\n",
       "         [    1,    48,    48,     5,   125,   564,   118,    17,    17,    17,\n",
       "              2,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0],\n",
       "         [    1,     5,    51,    52,   262,   758,    17,     2,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0],\n",
       "         [    1,  1925,    17,     2,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0],\n",
       "         [    1,   180,   190,    54,  2622,   118,    17,     2,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0],\n",
       "         [    1,     4,    27,    67,    16,   139,    35,   157,   128,   369,\n",
       "             47,    10,    16,    35,     2,     0,     0,     0,     0,     0,\n",
       "              0,     0],\n",
       "         [    1, 10758, 25123,    17,   198,   112,    13,   497,    77,    19,\n",
       "          25124,  5511,  2205, 25125,    17,     2,     0,     0,     0,     0,\n",
       "              0,     0],\n",
       "         [    1,   202,    53,    31,    17,     2,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0],\n",
       "         [    1,    27,    67,    16,    67,  4242,    35,     2,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0],\n",
       "         [    1,    54,  9830,   385,   217,  4531,    16,  1255,  2010,  7146,\n",
       "            217,    19,   596,  2734,   150,    19,  2064,    52,    17,    17,\n",
       "             17,     2],\n",
       "         [    1, 10649,    17,    13,    14,    19,    59,    44,     5,   139,\n",
       "             17,     2,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0],\n",
       "         [    1,  9909,    17,    17,    17,     2,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0],\n",
       "         [    1,  1267,    35,    16,   202,   101,   311,    54,   346,   211,\n",
       "             16,   202,   101,   717,  1607,    35,     2,     0,     0,     0,\n",
       "              0,     0],\n",
       "         [    1,    18,  1888,    17,     2,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0],\n",
       "         [    1,   819,   101,   788,    17,     2,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0],\n",
       "         [    1,  9418,    73,    54, 10925,    21,    54,  1681,   190,    54,\n",
       "          12399,    17,   200,    14,    18,    54, 17914,    17,     2,     0,\n",
       "              0,     0],\n",
       "         [    1,   758,    16,    66,    67,    17,   161,   103,    72,    77,\n",
       "            109,    17,     2,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0],\n",
       "         [    1,     7,   193,  2470,   391,   288,     5,   193,    43,  9742,\n",
       "             21,  1736,    18,  9743,    21,  9744,    17,     2,     0,     0,\n",
       "              0,     0],\n",
       "         [    1,   128,   741,   101,    53,   143,  5483,    10,    39,    17,\n",
       "              2,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0],\n",
       "         [    1,     5,   214,    52,   103,    72,    17,    17,    17,     5,\n",
       "            214,    52,   103,    72,   150,   158,    17,    17,    17,     2,\n",
       "              0,     0],\n",
       "         [    1,    48,    17,     5,   235,    93,    75,   149,    17,     2,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0],\n",
       "         [    1,    48,   201,    31,   984,  6350,    17,  1252,  1211,   459,\n",
       "           6353,   425,    17,     2,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0],\n",
       "         [    1,   133,    89,    17,    16,   603,   425,    40,  2010,    17,\n",
       "              5,   494,    52,   117,    12,    16,   348,    15,    17,     2,\n",
       "              0,     0],\n",
       "         [    1,     5, 14065,    72,   293,    43,  1194,     4,   201,   361,\n",
       "            198, 22633,    43,   573,   368,    17,     2,     0,     0,     0,\n",
       "              0,     0],\n",
       "         [    1,   602,    48,    17,    17,    17,     5,   262,    18,    13,\n",
       "            897,     2,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0],\n",
       "         [    1,   185,    36,   324,    17,     2,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0]]),\n",
       " [18,\n",
       "  17,\n",
       "  15,\n",
       "  15,\n",
       "  15,\n",
       "  14,\n",
       "  12,\n",
       "  11,\n",
       "  11,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  9,\n",
       "  9,\n",
       "  8,\n",
       "  8,\n",
       "  8,\n",
       "  8,\n",
       "  8,\n",
       "  8,\n",
       "  7,\n",
       "  6,\n",
       "  6,\n",
       "  6,\n",
       "  6,\n",
       "  6,\n",
       "  5,\n",
       "  5,\n",
       "  4,\n",
       "  4,\n",
       "  4],\n",
       " [11,\n",
       "  16,\n",
       "  8,\n",
       "  12,\n",
       "  12,\n",
       "  4,\n",
       "  4,\n",
       "  11,\n",
       "  8,\n",
       "  4,\n",
       "  8,\n",
       "  15,\n",
       "  16,\n",
       "  6,\n",
       "  8,\n",
       "  22,\n",
       "  12,\n",
       "  6,\n",
       "  17,\n",
       "  5,\n",
       "  6,\n",
       "  19,\n",
       "  13,\n",
       "  18,\n",
       "  11,\n",
       "  20,\n",
       "  10,\n",
       "  14,\n",
       "  20,\n",
       "  17,\n",
       "  12,\n",
       "  6])"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(dataloader))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e6f6e21",
   "metadata": {},
   "source": [
    "Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "ee717694",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, vocab_size,embedding_dim,hidden_dim,num_layers=1,dropout=.3):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.hidden_dim=hidden_dim\n",
    "        self.num_layers=num_layers\n",
    "        \n",
    "        self.embedding=nn.Embedding(num_embeddings=vocab_size,embedding_dim=embedding_dim,padding_idx=0)\n",
    "        self.lstm=nn.LSTM(input_size=embedding_dim,hidden_size=hidden_dim,num_layers=num_layers,batch_first=True,dropout= dropout)\n",
    "        \n",
    "    def forward(self,input,input_length):\n",
    "        embedded=self.embedding(input)\n",
    "        # print(\"Embedded shape:\", embedded.shape)\n",
    "        \n",
    "        packed=pack_padded_sequence(embedded,input_length,batch_first=True,enforce_sorted=True) # Packs variable-length sequences so the LSTM ignores padded time steps and processes only real tokens in each sequence\n",
    "        \n",
    "        packed_outputs,(hidden,cell)=self.lstm(packed)\n",
    "        \n",
    "        outputs,_=pad_packed_sequence(packed_outputs,batch_first=True) # Unpacks the LSTM outputs back to padded sequences for batch alignment\n",
    "\n",
    "            # print(\"Encoder outputs shape:\", outputs.shape)\n",
    "            # print(\"Encoder hidden shape:\", hidden.shape)\n",
    "            # print(\"Encoder cell shape:\", cell.shape)\n",
    "        \n",
    "        return outputs,(hidden,cell)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "5764bcb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\LENOVO\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3 and num_layers=1\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "VOCAB_SIZE = vocab.next_num\n",
    "EMBEDDING_DIM = 256\n",
    "HIDDEN_DIM = 512\n",
    "NUM_LAYERS = 1\n",
    "\n",
    "encoder = Encoder(\n",
    "    vocab_size=VOCAB_SIZE,\n",
    "    embedding_dim=EMBEDDING_DIM,\n",
    "    hidden_dim=HIDDEN_DIM,\n",
    "    num_layers=NUM_LAYERS\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "5db2bd9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input tensor shape: torch.Size([32, 22])\n"
     ]
    }
   ],
   "source": [
    "encoder.eval()  # evaluation mode\n",
    "\n",
    "batch = next(iter(dataloader))\n",
    "input_tensor, target_tensor, input_lengths, target_lengths = batch\n",
    "\n",
    "print(\"Input tensor shape:\", input_tensor.shape)\n",
    "\n",
    "with torch.no_grad():\n",
    "    encoder_outputs, (hidden, cell) = encoder(input_tensor, input_lengths)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "291a7477",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self,vocab_size,embedding_dim,hidden_dim, num_layers=1,dropout=.3):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.hidden_dim=hidden_dim\n",
    "        self.num_layers=num_layers\n",
    "        \n",
    "        self.embedding=nn.Embedding(num_embeddings=vocab_size,embedding_dim=embedding_dim,padding_idx=0)\n",
    "        self.lstm=nn.LSTM(input_size=embedding_dim,hidden_size=hidden_dim,num_layers=num_layers,batch_first=True,dropout= dropout)\n",
    "        # fc layer to map LSTM outputs to vocab size\n",
    "        self.fc_out=nn.Linear(hidden_dim,vocab_size)\n",
    "        self.dropout=nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self,input,hidden,cell):\n",
    "        # input shape: (batch_size) -> we process one time step at a time\n",
    "        input=input.unsqueeze(1)  # (batch_size, 1) # add time step dimension\n",
    "        \n",
    "        embedded=self.dropout(self.embedding(input))  # (batch_size, 1, embedding_dim)\n",
    "        \n",
    "        outputs,(hidden,cell)=self.lstm(embedded,(hidden,cell))  # outputs: (batch_size, 1, hidden_dim)\n",
    "        \n",
    "        predictions=self.fc_out(outputs.squeeze(1))  # (batch_size, vocab_size) remove the time step dimension\n",
    "        \n",
    "        return predictions,hidden,cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "ac7129cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder = Decoder(\n",
    "    vocab_size=vocab.next_num,\n",
    "    embedding_dim=EMBEDDING_DIM,\n",
    "    hidden_dim=HIDDEN_DIM,\n",
    "    num_layers=NUM_LAYERS\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "4a7c16b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def decode_training(decoder,encoder_hidden,encoder_cell,target_tensor,teacher_forcing_ratio=0.5):\n",
    "    \n",
    "    batch_size = target_tensor.size(0)\n",
    "    max_len = target_tensor.size(1)\n",
    "\n",
    "    decoder_input = torch.full((batch_size,),vocab.SOS_token,dtype=torch.long,device=target_tensor.device)\n",
    "\n",
    "    hidden = encoder_hidden\n",
    "    cell = encoder_cell\n",
    "\n",
    "    all_outputs = []\n",
    "\n",
    "    for t in range(max_len):\n",
    "        \n",
    "        logits, hidden, cell = decoder(decoder_input, hidden, cell)\n",
    "        \n",
    "        all_outputs.append(logits.unsqueeze(1))\n",
    "\n",
    "        use_teacher_forcing = random.random() < teacher_forcing_ratio\n",
    "\n",
    "        if use_teacher_forcing:\n",
    "            decoder_input = target_tensor[:, t]\n",
    "        else:\n",
    "            decoder_input = logits.argmax(dim=1)\n",
    "\n",
    "    outputs = torch.cat(all_outputs, dim=1)\n",
    "    # shape: (batch_size, max_len, vocab_size)\n",
    "\n",
    "    return outputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "19940500",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "encoder_optimizer = optim.Adam(encoder.parameters(), lr=0.001)\n",
    "decoder_optimizer = optim.Adam(decoder.parameters(), lr=0.001)\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=vocab.PAD_token)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "a5baee91",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(encoder,decoder,input_tensor,target_tensor,input_lengths, encoder_optimizer,decoder_optimizer,criterion,teacher_forcing_ratio=0.5):\n",
    "    \n",
    "    encoder.train()\n",
    "    decoder.train()\n",
    "\n",
    "    encoder_optimizer.zero_grad()\n",
    "    decoder_optimizer.zero_grad()\n",
    "\n",
    "    # ENCODER\n",
    "    encoder_outputs, (hidden, cell) = encoder(input_tensor, input_lengths)\n",
    "\n",
    "    # DECODER\n",
    "    decoder_outputs = decode_training(decoder,hidden,cell,target_tensor,teacher_forcing_ratio)\n",
    "    # decoder_outputs: (batch, seq_len, vocab_size)\n",
    "\n",
    "    # LOSS\n",
    "    loss = criterion(decoder_outputs.view(-1, decoder_outputs.size(-1)),target_tensor.view(-1))\n",
    "\n",
    "    # ----- Backprop -----\n",
    "    loss.backward()\n",
    "\n",
    "    # Gradient clipping (important for RNNs)\n",
    "    torch.nn.utils.clip_grad_norm_(encoder.parameters(), 1.0)\n",
    "    torch.nn.utils.clip_grad_norm_(decoder.parameters(), 1.0)\n",
    "\n",
    "    encoder_optimizer.step()\n",
    "    decoder_optimizer.step()\n",
    "\n",
    "    return loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "f6e1f2bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n",
      "GPU available: False\n"
     ]
    }
   ],
   "source": [
    "# Setup GPU device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "print(f\"GPU available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU Name: {torch.cuda.get_device_name(0)}\")\n",
    "\n",
    "# Move models to device\n",
    "encoder = encoder.to(device)\n",
    "decoder = decoder.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f93e5020",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "EPOCHS = 10\n",
    "PRINT_EVERY = 100\n",
    "\n",
    "for epoch in range(1, EPOCHS + 1):\n",
    "    total_loss = 0\n",
    "\n",
    "    for i, batch in tqdm(enumerate(dataloader, start=1), total=len(dataloader)):\n",
    "        input_tensor, target_tensor, input_lengths, target_lengths = batch\n",
    "        \n",
    "        # Move tensors to GPU\n",
    "        input_tensor = input_tensor.to(device)\n",
    "        target_tensor = target_tensor.to(device)\n",
    "\n",
    "        loss = train_step(\n",
    "            encoder,\n",
    "            decoder,\n",
    "            input_tensor,\n",
    "            target_tensor,\n",
    "            input_lengths,\n",
    "            encoder_optimizer,\n",
    "            decoder_optimizer,\n",
    "            criterion,\n",
    "            teacher_forcing_ratio=0.5\n",
    "        )\n",
    "\n",
    "        total_loss += loss\n",
    "\n",
    "        if i % PRINT_EVERY == 0:\n",
    "            print(\n",
    "                f\"Epoch [{epoch}/{EPOCHS}] \"\n",
    "                f\"Step [{i}/{len(dataloader)}] \"\n",
    "                f\"Loss: {loss:.4f}\"\n",
    "            )\n",
    "\n",
    "    avg_loss = total_loss / len(dataloader)\n",
    "    print(f\"\\n Epoch {epoch} completed | Avg Loss: {avg_loss:.4f}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbcff532",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat(\n",
    "    encoder,\n",
    "    decoder,\n",
    "    sentence,\n",
    "    vocab,\n",
    "    device,\n",
    "    max_len=20\n",
    "):\n",
    "    encoder.eval()\n",
    "    decoder.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        # Prepare input\n",
    "        input_seq = sentence_to_indices(vocab, normalize_text(sentence))\n",
    "        input_tensor = torch.tensor(input_seq).unsqueeze(0).to(device)\n",
    "        input_lengths = [len(input_seq)]\n",
    "\n",
    "        # Encoder\n",
    "        encoder_outputs, (hidden, cell) = encoder(input_tensor, input_lengths)\n",
    "\n",
    "        # Decoder\n",
    "        decoder_input = torch.tensor([vocab.SOS_token]).to(device)\n",
    "        decoded_words = []\n",
    "\n",
    "        for _ in range(max_len):\n",
    "            logits, hidden, cell = decoder(decoder_input, hidden, cell)\n",
    "            next_token = logits.argmax(dim=1).item()\n",
    "\n",
    "            if next_token == vocab.EOS_token:\n",
    "                break\n",
    "\n",
    "            decoded_words.append(vocab.index2word[next_token])\n",
    "            decoder_input = torch.tensor([next_token]).to(device)\n",
    "\n",
    "    return \" \".join(decoded_words)\n",
    "\n",
    "while True:\n",
    "    user_input = input(\"You: \")\n",
    "    if user_input.lower() in [\"quit\", \"exit\"]:\n",
    "        break\n",
    "\n",
    "    reply = chat(encoder, decoder, user_input, vocab, device)\n",
    "    print(\"Bot:\", reply)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ec51e07",
   "metadata": {},
   "source": [
    "You:  im hungry\n",
    "\n",
    "Bot: <SOS> you got a .\n",
    "\n",
    "You:  i wanna go out tonight\n",
    "\n",
    "Bot: <SOS> yeah .\n",
    "\n",
    "You:  quit\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
