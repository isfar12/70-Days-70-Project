{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "43f955cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import T5Tokenizer, T5ForConditionalGeneration, T5Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "01897cec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install sentencepiece"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5f4cdf6",
   "metadata": {},
   "source": [
    "# Option 1: Using T5 Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ee7e5cb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n"
     ]
    }
   ],
   "source": [
    "#initialize the model and tokenizer\n",
    "model_name = 't5-small'\n",
    "tokenizer = T5Tokenizer.from_pretrained(model_name)\n",
    "config = T5Config.from_pretrained(model_name)\n",
    "model = T5ForConditionalGeneration.from_pretrained(model_name, config=config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e006bb5f",
   "metadata": {},
   "source": [
    "T5 models expect the input text to be prefixed with a task-specific prompt, such as \"summarize: \" for summarization tasks. This helps the model understand what kind of output is expected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "721fbd83",
   "metadata": {},
   "outputs": [],
   "source": [
    "text=\"\"\"We all know that OpenAI actually started the trend of AI tools after releasing ChatGPT.\n",
    "\n",
    "After that, we saw everyone shift to AI. Developers and big companies began building AI tools, and even individuals started learning about artificial intelligence.\n",
    "\n",
    "Thanks to that, we have tons of popular AI tools like RunwayML, Lovable, Claude, Gemini, Perplexity, Cursor, Stitch, NotebookLM, Leonardo AI, Framer AI, and the list goes on.\n",
    "\n",
    "That's not all. Every day, tons of new AI tools are launched, which makes it difficult for people to find the best ones for their needs.\n",
    "\n",
    "That's why I spend a lot of time testing some of the best new AI tools and write a couple of posts every month to share the ones that truly stand out.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "16fddf93",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import html\n",
    "# modified with GPT for best practices\n",
    "def clean_text(text):\n",
    "    text = html.unescape(text)\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'<.*?>', ' ', text)             # remove HTML\n",
    "    text = re.sub(r'http\\S+|www\\.\\S+', ' ', text)  # remove URLs\n",
    "    text = re.sub(r'\\S+@\\S+', ' ', text)           # remove emails\n",
    "    text = re.sub(r\"(.)\\1{2,}\", r\"\\1\\1\", text)     # soooo -> soo\n",
    "\n",
    "    # keep ! and ? (sentiment)\n",
    "    text = re.sub(r'[^a-z!? ]', ' ', text)\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "60dffac2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "127"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_text=clean_text(text).split()\n",
    "len(cleaned_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "af12d5dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[21603,    10,    62,    66,   214,    24,   539,     9,    23,   700,\n",
      "           708,     8,  4166,    13,     3,     9,    23,  1339,   227,     3,\n",
      "         16306,  3582,   122,   102,    17,   227,    24,    62,  1509,   921,\n",
      "          4108,    12,     3,     9,    23,  5564,    11,   600,   688,  1553,\n",
      "           740,     3,     9,    23,  1339,    11,   237,  1742,   708,  1036,\n",
      "            81,  7353,  6123,  2049,    12,    24,    62,    43,  8760,    13,\n",
      "          1012,     3,     9,    23,  1339,   114, 22750,    51,    40,     3,\n",
      "          5850,   179,     3,    75, 12513,    15,   873,  7619,   399,  9247,\n",
      "           485,  8385,   127, 12261, 16638,    40,    51,    90,   106,   986,\n",
      "            32,     3,     9,    23,  2835,    52,     3,     9,    23,    11,\n",
      "             8,   570,  1550,    30,    24,     3,     7,    59,    66,   334,\n",
      "           239,  8760,    13,   126,     3,     9,    23,  1339,    33,  3759,\n",
      "            84,   656,    34,  1256,    21,   151,    12,   253,     8,   200,\n",
      "          2102,    21,    70,   523,    24,     3,     7,   572,     3,    23,\n",
      "          1492,     3,     9,   418,    13,    97,  2505,   128,    13,     8,\n",
      "           200,   126,     3,     9,    23,  1339,    11,  1431,     3,     9,\n",
      "          1158,    13,  3489,   334,   847,    12,   698,     8,  2102,    24,\n",
      "          1892,  1518,    91,     1]])\n"
     ]
    }
   ],
   "source": [
    "tokenized_text=tokenizer.encode(\"summarize: \" + clean_text(text), return_tensors=\"pt\", max_length=512, truncation=True)\n",
    "print(tokenized_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "0ef34c0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary:\n",
      "openai has tons of popular ai tools like runwayml lovable claude gemini perplexity cursor stitch notebooklm leonardo ai framer ai. the list goes on that s not all every day tons of new ai tools are launched which makes it difficult for people to find the best ones for their needs.\n",
      "51\n"
     ]
    }
   ],
   "source": [
    "summary_ids=model.generate(tokenized_text, max_length=150, min_length=40, length_penalty=2.0, num_beams=4, early_stopping=True)\n",
    "summary=tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
    "\n",
    "print(\"Summary:\")\n",
    "print(summary)\n",
    "print(len(summary.split()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1860326",
   "metadata": {},
   "source": [
    "# Option 2 : Using Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "75e531e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\LENOVO\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'summary_text': \"Every day, tons of new AI tools are launched, which makes it difficult for people to find the best ones for their needs. That's why I spend a lot of time testing some of the best newAI tools and write a couple of posts every month to share the ones that truly stand out.\"}]\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "summarizer = pipeline(\"summarization\", model=\"facebook/bart-large-cnn\")\n",
    "summary = summarizer(text, max_length=130, min_length=30)\n",
    "\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e82490ec",
   "metadata": {},
   "source": [
    "# Option 3: LSTM/GRU/RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "f0b23635",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['business', 'entertainment', 'politics', 'sport', 'tech'],\n",
       " ['business', 'entertainment', 'politics', 'sport', 'tech'])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from glob import glob\n",
    "from pathlib import Path\n",
    "\n",
    "news_files = Path(\"E:\\\\70 Days 70 Project\\\\Text Summarization\\\\data\\\\BBC News Summary\\\\News Articles\")\n",
    "summaries_files = Path(\"E:\\\\70 Days 70 Project\\\\Text Summarization\\\\data\\\\BBC News Summary\\\\Summaries\")\n",
    "\n",
    "news_categories=os.listdir(news_files)\n",
    "summary_categories=os.listdir(summaries_files)\n",
    "news_categories,summary_categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "483040d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "001.txt\n",
      "002.txt\n",
      "003.txt\n",
      "004.txt\n",
      "005.txt\n",
      "006.txt\n",
      "007.txt\n",
      "008.txt\n",
      "009.txt\n",
      "010.txt\n",
      "011.txt\n",
      "012.txt\n",
      "013.txt\n",
      "014.txt\n",
      "015.txt\n",
      "016.txt\n",
      "017.txt\n",
      "018.txt\n",
      "019.txt\n",
      "020.txt\n",
      "021.txt\n",
      "022.txt\n",
      "023.txt\n",
      "024.txt\n",
      "025.txt\n",
      "026.txt\n",
      "027.txt\n",
      "028.txt\n",
      "029.txt\n",
      "030.txt\n",
      "031.txt\n",
      "032.txt\n",
      "033.txt\n",
      "034.txt\n",
      "035.txt\n",
      "036.txt\n",
      "037.txt\n",
      "038.txt\n",
      "039.txt\n",
      "040.txt\n",
      "041.txt\n",
      "042.txt\n",
      "043.txt\n",
      "044.txt\n",
      "045.txt\n",
      "046.txt\n",
      "047.txt\n",
      "048.txt\n",
      "049.txt\n",
      "050.txt\n",
      "051.txt\n",
      "052.txt\n",
      "053.txt\n",
      "054.txt\n",
      "055.txt\n",
      "056.txt\n",
      "057.txt\n",
      "058.txt\n",
      "059.txt\n",
      "060.txt\n",
      "061.txt\n",
      "062.txt\n",
      "063.txt\n",
      "064.txt\n",
      "065.txt\n",
      "066.txt\n",
      "067.txt\n",
      "068.txt\n",
      "069.txt\n",
      "070.txt\n",
      "071.txt\n",
      "072.txt\n",
      "073.txt\n",
      "074.txt\n",
      "075.txt\n",
      "076.txt\n",
      "077.txt\n",
      "078.txt\n",
      "079.txt\n",
      "080.txt\n",
      "081.txt\n",
      "082.txt\n",
      "083.txt\n",
      "084.txt\n",
      "085.txt\n",
      "086.txt\n",
      "087.txt\n",
      "088.txt\n",
      "089.txt\n",
      "090.txt\n",
      "091.txt\n",
      "092.txt\n",
      "093.txt\n",
      "094.txt\n",
      "095.txt\n",
      "096.txt\n",
      "097.txt\n",
      "098.txt\n",
      "099.txt\n",
      "100.txt\n",
      "101.txt\n",
      "102.txt\n",
      "103.txt\n",
      "104.txt\n",
      "105.txt\n",
      "106.txt\n",
      "107.txt\n",
      "108.txt\n",
      "109.txt\n",
      "110.txt\n",
      "111.txt\n",
      "112.txt\n",
      "113.txt\n",
      "114.txt\n",
      "115.txt\n",
      "116.txt\n",
      "117.txt\n",
      "118.txt\n",
      "119.txt\n",
      "120.txt\n",
      "121.txt\n",
      "122.txt\n",
      "123.txt\n",
      "124.txt\n",
      "125.txt\n",
      "126.txt\n",
      "127.txt\n",
      "128.txt\n",
      "129.txt\n",
      "130.txt\n",
      "131.txt\n",
      "132.txt\n",
      "133.txt\n",
      "134.txt\n",
      "135.txt\n",
      "136.txt\n",
      "137.txt\n",
      "138.txt\n",
      "139.txt\n",
      "140.txt\n",
      "141.txt\n",
      "142.txt\n",
      "143.txt\n",
      "144.txt\n",
      "145.txt\n",
      "146.txt\n",
      "147.txt\n",
      "148.txt\n",
      "149.txt\n",
      "150.txt\n",
      "151.txt\n",
      "152.txt\n",
      "153.txt\n",
      "154.txt\n",
      "155.txt\n",
      "156.txt\n",
      "157.txt\n",
      "158.txt\n",
      "159.txt\n",
      "160.txt\n",
      "161.txt\n",
      "162.txt\n",
      "163.txt\n",
      "164.txt\n",
      "165.txt\n",
      "166.txt\n",
      "167.txt\n",
      "168.txt\n",
      "169.txt\n",
      "170.txt\n",
      "171.txt\n",
      "172.txt\n",
      "173.txt\n",
      "174.txt\n",
      "175.txt\n",
      "176.txt\n",
      "177.txt\n",
      "178.txt\n",
      "179.txt\n",
      "180.txt\n",
      "181.txt\n",
      "182.txt\n",
      "183.txt\n",
      "184.txt\n",
      "185.txt\n",
      "186.txt\n",
      "187.txt\n",
      "188.txt\n",
      "189.txt\n",
      "190.txt\n",
      "191.txt\n",
      "192.txt\n",
      "193.txt\n",
      "194.txt\n",
      "195.txt\n",
      "196.txt\n",
      "197.txt\n",
      "198.txt\n",
      "199.txt\n",
      "200.txt\n",
      "201.txt\n",
      "202.txt\n",
      "203.txt\n",
      "204.txt\n",
      "205.txt\n",
      "206.txt\n",
      "207.txt\n",
      "208.txt\n",
      "209.txt\n",
      "210.txt\n",
      "211.txt\n",
      "212.txt\n",
      "213.txt\n",
      "214.txt\n",
      "215.txt\n",
      "216.txt\n",
      "217.txt\n",
      "218.txt\n",
      "219.txt\n",
      "220.txt\n",
      "221.txt\n",
      "222.txt\n",
      "223.txt\n",
      "224.txt\n",
      "225.txt\n",
      "226.txt\n",
      "227.txt\n",
      "228.txt\n",
      "229.txt\n",
      "230.txt\n",
      "231.txt\n",
      "232.txt\n",
      "233.txt\n",
      "234.txt\n",
      "235.txt\n",
      "236.txt\n",
      "237.txt\n",
      "238.txt\n",
      "239.txt\n",
      "240.txt\n",
      "241.txt\n",
      "242.txt\n",
      "243.txt\n",
      "244.txt\n",
      "245.txt\n",
      "246.txt\n",
      "247.txt\n",
      "248.txt\n",
      "249.txt\n",
      "250.txt\n",
      "251.txt\n",
      "252.txt\n",
      "253.txt\n",
      "254.txt\n",
      "255.txt\n",
      "256.txt\n",
      "257.txt\n",
      "258.txt\n",
      "259.txt\n",
      "260.txt\n",
      "261.txt\n",
      "262.txt\n",
      "263.txt\n",
      "264.txt\n",
      "265.txt\n",
      "266.txt\n",
      "267.txt\n",
      "268.txt\n",
      "269.txt\n",
      "270.txt\n",
      "271.txt\n",
      "272.txt\n",
      "273.txt\n",
      "274.txt\n",
      "275.txt\n",
      "276.txt\n",
      "277.txt\n",
      "278.txt\n",
      "279.txt\n",
      "280.txt\n",
      "281.txt\n",
      "282.txt\n",
      "283.txt\n",
      "284.txt\n",
      "285.txt\n",
      "286.txt\n",
      "287.txt\n",
      "288.txt\n",
      "289.txt\n",
      "290.txt\n",
      "291.txt\n",
      "292.txt\n",
      "293.txt\n",
      "294.txt\n",
      "295.txt\n",
      "296.txt\n",
      "297.txt\n",
      "298.txt\n",
      "299.txt\n",
      "300.txt\n",
      "301.txt\n",
      "302.txt\n",
      "303.txt\n",
      "304.txt\n",
      "305.txt\n",
      "306.txt\n",
      "307.txt\n",
      "308.txt\n",
      "309.txt\n",
      "310.txt\n",
      "311.txt\n",
      "312.txt\n",
      "313.txt\n",
      "314.txt\n",
      "315.txt\n",
      "316.txt\n",
      "317.txt\n",
      "318.txt\n",
      "319.txt\n",
      "320.txt\n",
      "321.txt\n",
      "322.txt\n",
      "323.txt\n",
      "324.txt\n",
      "325.txt\n",
      "326.txt\n",
      "327.txt\n",
      "328.txt\n",
      "329.txt\n",
      "330.txt\n",
      "331.txt\n",
      "332.txt\n",
      "333.txt\n",
      "334.txt\n",
      "335.txt\n",
      "336.txt\n",
      "337.txt\n",
      "338.txt\n",
      "339.txt\n",
      "340.txt\n",
      "341.txt\n",
      "342.txt\n",
      "343.txt\n",
      "344.txt\n",
      "345.txt\n",
      "346.txt\n",
      "347.txt\n",
      "348.txt\n",
      "349.txt\n",
      "350.txt\n",
      "351.txt\n",
      "352.txt\n",
      "353.txt\n",
      "354.txt\n",
      "355.txt\n",
      "356.txt\n",
      "357.txt\n",
      "358.txt\n",
      "359.txt\n",
      "360.txt\n",
      "361.txt\n",
      "362.txt\n",
      "363.txt\n",
      "364.txt\n",
      "365.txt\n",
      "366.txt\n",
      "367.txt\n",
      "368.txt\n",
      "369.txt\n",
      "370.txt\n",
      "371.txt\n",
      "372.txt\n",
      "373.txt\n",
      "374.txt\n",
      "375.txt\n",
      "376.txt\n",
      "377.txt\n",
      "378.txt\n",
      "379.txt\n",
      "380.txt\n",
      "381.txt\n",
      "382.txt\n",
      "383.txt\n",
      "384.txt\n",
      "385.txt\n",
      "386.txt\n",
      "387.txt\n",
      "388.txt\n",
      "389.txt\n",
      "390.txt\n",
      "391.txt\n",
      "392.txt\n",
      "393.txt\n",
      "394.txt\n",
      "395.txt\n",
      "396.txt\n",
      "397.txt\n",
      "398.txt\n",
      "399.txt\n",
      "400.txt\n",
      "401.txt\n",
      "402.txt\n",
      "403.txt\n",
      "404.txt\n",
      "405.txt\n",
      "406.txt\n",
      "407.txt\n",
      "408.txt\n",
      "409.txt\n",
      "410.txt\n",
      "411.txt\n",
      "412.txt\n",
      "413.txt\n",
      "414.txt\n",
      "415.txt\n",
      "416.txt\n",
      "417.txt\n",
      "418.txt\n",
      "419.txt\n",
      "420.txt\n",
      "421.txt\n",
      "422.txt\n",
      "423.txt\n",
      "424.txt\n",
      "425.txt\n",
      "426.txt\n",
      "427.txt\n",
      "428.txt\n",
      "429.txt\n",
      "430.txt\n",
      "431.txt\n",
      "432.txt\n",
      "433.txt\n",
      "434.txt\n",
      "435.txt\n",
      "436.txt\n",
      "437.txt\n",
      "438.txt\n",
      "439.txt\n",
      "440.txt\n",
      "441.txt\n",
      "442.txt\n",
      "443.txt\n",
      "444.txt\n",
      "445.txt\n",
      "446.txt\n",
      "447.txt\n",
      "448.txt\n",
      "449.txt\n",
      "450.txt\n",
      "451.txt\n",
      "452.txt\n",
      "453.txt\n",
      "454.txt\n",
      "455.txt\n",
      "456.txt\n",
      "457.txt\n",
      "458.txt\n",
      "459.txt\n",
      "460.txt\n",
      "461.txt\n",
      "462.txt\n",
      "463.txt\n",
      "464.txt\n",
      "465.txt\n",
      "466.txt\n",
      "467.txt\n",
      "468.txt\n",
      "469.txt\n",
      "470.txt\n",
      "471.txt\n",
      "472.txt\n",
      "473.txt\n",
      "474.txt\n",
      "475.txt\n",
      "476.txt\n",
      "477.txt\n",
      "478.txt\n",
      "479.txt\n",
      "480.txt\n",
      "481.txt\n",
      "482.txt\n",
      "483.txt\n",
      "484.txt\n",
      "485.txt\n",
      "486.txt\n",
      "487.txt\n",
      "488.txt\n",
      "489.txt\n",
      "490.txt\n",
      "491.txt\n",
      "492.txt\n",
      "493.txt\n",
      "494.txt\n",
      "495.txt\n",
      "496.txt\n",
      "497.txt\n",
      "498.txt\n",
      "499.txt\n",
      "500.txt\n",
      "501.txt\n",
      "502.txt\n",
      "503.txt\n",
      "504.txt\n",
      "505.txt\n",
      "506.txt\n",
      "507.txt\n",
      "508.txt\n",
      "509.txt\n",
      "510.txt\n"
     ]
    }
   ],
   "source": [
    "for files in os.listdir(Path(news_files/news_categories[0])):\n",
    "    print(files)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b96c2f9a",
   "metadata": {},
   "source": [
    "Ref: https://www.kaggle.com/code/mallaavinash/text-summarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "ba2cc21f",
   "metadata": {},
   "outputs": [],
   "source": [
    "contraction_mapping = {\"ain't\": \"is not\", \"aren't\": \"are not\",\"can't\": \"cannot\", \"'cause\": \"because\", \"could've\": \"could have\", \"couldn't\": \"could not\",\n",
    "\n",
    "                           \"didn't\": \"did not\", \"doesn't\": \"does not\", \"don't\": \"do not\", \"hadn't\": \"had not\", \"hasn't\": \"has not\", \"haven't\": \"have not\",\n",
    "\n",
    "                           \"he'd\": \"he would\",\"he'll\": \"he will\", \"he's\": \"he is\", \"how'd\": \"how did\", \"how'd'y\": \"how do you\", \"how'll\": \"how will\", \"how's\": \"how is\",\n",
    "\n",
    "                           \"I'd\": \"I would\", \"I'd've\": \"I would have\", \"I'll\": \"I will\", \"I'll've\": \"I will have\",\"I'm\": \"I am\", \"I've\": \"I have\", \"i'd\": \"i would\",\n",
    "\n",
    "                           \"i'd've\": \"i would have\", \"i'll\": \"i will\",  \"i'll've\": \"i will have\",\"i'm\": \"i am\", \"i've\": \"i have\", \"isn't\": \"is not\", \"it'd\": \"it would\",\n",
    "\n",
    "                           \"it'd've\": \"it would have\", \"it'll\": \"it will\", \"it'll've\": \"it will have\",\"it's\": \"it is\", \"let's\": \"let us\", \"ma'am\": \"madam\",\n",
    "\n",
    "                           \"mayn't\": \"may not\", \"might've\": \"might have\",\"mightn't\": \"might not\",\"mightn't've\": \"might not have\", \"must've\": \"must have\",\n",
    "                            \"mustn't\": \"must not\", \"mustn't've\": \"must not have\", \"needn't\": \"need not\", \"needn't've\": \"need not have\",\"o'clock\": \"of the clock\",\n",
    "\n",
    "                           \"oughtn't\": \"ought not\", \"oughtn't've\": \"ought not have\", \"shan't\": \"shall not\", \"sha'n't\": \"shall not\", \"shan't've\": \"shall not have\",\n",
    "\n",
    "                           \"she'd\": \"she would\", \"she'd've\": \"she would have\", \"she'll\": \"she will\", \"she'll've\": \"she will have\", \"she's\": \"she is\",\n",
    "\n",
    "                           \"should've\": \"should have\", \"shouldn't\": \"should not\", \"shouldn't've\": \"should not have\", \"so've\": \"so have\",\"so's\": \"so as\",\n",
    "\n",
    "                           \"this's\": \"this is\",\"that'd\": \"that would\", \"that'd've\": \"that would have\", \"that's\": \"that is\", \"there'd\": \"there would\",\n",
    "\n",
    "                           \"there'd've\": \"there would have\", \"there's\": \"there is\", \"here's\": \"here is\",\"they'd\": \"they would\", \"they'd've\": \"they would have\",\n",
    "                           \"they'll\": \"they will\", \"they'll've\": \"they will have\", \"they're\": \"they are\", \"they've\": \"they have\", \"to've\": \"to have\",\n",
    "\n",
    "                           \"wasn't\": \"was not\", \"we'd\": \"we would\", \"we'd've\": \"we would have\", \"we'll\": \"we will\", \"we'll've\": \"we will have\", \"we're\": \"we are\",\n",
    "\n",
    "                           \"we've\": \"we have\", \"weren't\": \"were not\", \"what'll\": \"what will\", \"what'll've\": \"what will have\", \"what're\": \"what are\",\n",
    "\n",
    "                           \"what's\": \"what is\", \"what've\": \"what have\", \"when's\": \"when is\", \"when've\": \"when have\", \"where'd\": \"where did\", \"where's\": \"where is\",\n",
    "\n",
    "                           \"where've\": \"where have\", \"who'll\": \"who will\", \"who'll've\": \"who will have\", \"who's\": \"who is\", \"who've\": \"who have\",\n",
    "\n",
    "                           \"why's\": \"why is\", \"why've\": \"why have\", \"will've\": \"will have\", \"won't\": \"will not\", \"won't've\": \"will not have\",\n",
    "\n",
    "                           \"would've\": \"would have\", \"wouldn't\": \"would not\", \"wouldn't've\": \"would not have\", \"y'all\": \"you all\",\n",
    "                           \"y'all'd\": \"you all would\",\"y'all'd've\": \"you all would have\",\"y'all're\": \"you all are\",\"y'all've\": \"you all have\",\n",
    "\n",
    "                           \"you'd\": \"you would\", \"you'd've\": \"you would have\", \"you'll\": \"you will\", \"you'll've\": \"you will have\",\n",
    "\n",
    "                           \"you're\": \"you are\", \"you've\": \"you have\"}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "97254065",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import html\n",
    "# modified with GPT for best practices\n",
    "def clean_text(text):\n",
    "    text = html.unescape(text)\n",
    "    text = text.lower()\n",
    "    text=' '.join([contraction_mapping[i] if i in contraction_mapping.keys() else i for i in text.split()])\n",
    "    text = re.sub(r'<.*?>', ' ', text)             # remove HTML\n",
    "    text = re.sub(r'http\\S+|www\\.\\S+', ' ', text)  # remove URLs\n",
    "    text = re.sub(r'\\S+@\\S+', ' ', text)           # remove emails\n",
    "    text = re.sub(r\"(.)\\1{2,}\", r\"\\1\\1\", text)     # soooo -> soo\n",
    "\n",
    "    # keep ! and ? (sentiment)\n",
    "    text = re.sub(r'[^a-z!? ]', ' ', text)\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0158e3c",
   "metadata": {},
   "source": [
    "#### Run once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "e0c50ee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# from tqdm import tqdm\n",
    "\n",
    "# dataframe={'news':[], 'summary':[]}\n",
    "\n",
    "# for category in news_categories:\n",
    "#     for file in tqdm(os.listdir(Path(news_files/category)),desc=f\"News Category: {category}\"):\n",
    "#         with open(Path(news_files/category/file), 'r', encoding='utf-8', errors='replace') as news_file:\n",
    "#             news_content=news_file.read()\n",
    "#             dataframe['news'].append(news_content)\n",
    "#     for file in tqdm(os.listdir(Path(summaries_files/category)),desc=f\"Summary Category: {category}\"):\n",
    "#         with open(Path(summaries_files/category/file), 'r', encoding='utf-8', errors='replace') as summary_file:\n",
    "#             summary_content=summary_file.read()\n",
    "#             dataframe['summary'].append(summary_content)\n",
    "# df=pd.DataFrame(dataframe)\n",
    "# df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "c93dce6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "fe85432c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.to_csv(\"bbc_news_summary_dataset.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "a17743ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>news</th>\n",
       "      <th>summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ad sales boost Time Warner profit\\n\\nQuarterly...</td>\n",
       "      <td>TimeWarner said fourth quarter sales rose 2% t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Dollar gains on Greenspan speech\\n\\nThe dollar...</td>\n",
       "      <td>The dollar has hit its highest level against t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Yukos unit buyer faces loan claim\\n\\nThe owner...</td>\n",
       "      <td>Yukos' owner Menatep Group says it will ask Ro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>High fuel prices hit BA's profits\\n\\nBritish A...</td>\n",
       "      <td>Rod Eddington, BA's chief executive, said the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Pernod takeover talk lifts Domecq\\n\\nShares in...</td>\n",
       "      <td>Pernod has reduced the debt it took on to fund...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                news  \\\n",
       "0  Ad sales boost Time Warner profit\\n\\nQuarterly...   \n",
       "1  Dollar gains on Greenspan speech\\n\\nThe dollar...   \n",
       "2  Yukos unit buyer faces loan claim\\n\\nThe owner...   \n",
       "3  High fuel prices hit BA's profits\\n\\nBritish A...   \n",
       "4  Pernod takeover talk lifts Domecq\\n\\nShares in...   \n",
       "\n",
       "                                             summary  \n",
       "0  TimeWarner said fourth quarter sales rose 2% t...  \n",
       "1  The dollar has hit its highest level against t...  \n",
       "2  Yukos' owner Menatep Group says it will ask Ro...  \n",
       "3  Rod Eddington, BA's chief executive, said the ...  \n",
       "4  Pernod has reduced the debt it took on to fund...  "
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df=pd.read_csv(\"bbc_news_summary_dataset.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "857d9ae7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>news</th>\n",
       "      <th>summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ad sales boost time warner profit quarterly pr...</td>\n",
       "      <td>timewarner said fourth quarter sales rose to b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>dollar gains on greenspan speech the dollar ha...</td>\n",
       "      <td>the dollar has hit its highest level against t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>yukos unit buyer faces loan claim the owners o...</td>\n",
       "      <td>yukos owner menatep group says it will ask ros...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>high fuel prices hit ba s profits british airw...</td>\n",
       "      <td>rod eddington ba s chief executive said the re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>pernod takeover talk lifts domecq shares in uk...</td>\n",
       "      <td>pernod has reduced the debt it took on to fund...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                news  \\\n",
       "0  ad sales boost time warner profit quarterly pr...   \n",
       "1  dollar gains on greenspan speech the dollar ha...   \n",
       "2  yukos unit buyer faces loan claim the owners o...   \n",
       "3  high fuel prices hit ba s profits british airw...   \n",
       "4  pernod takeover talk lifts domecq shares in uk...   \n",
       "\n",
       "                                             summary  \n",
       "0  timewarner said fourth quarter sales rose to b...  \n",
       "1  the dollar has hit its highest level against t...  \n",
       "2  yukos owner menatep group says it will ask ros...  \n",
       "3  rod eddington ba s chief executive said the re...  \n",
       "4  pernod has reduced the debt it took on to fund...  "
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"news\"]=df[\"news\"].apply(lambda x: clean_text(x))\n",
    "df[\"summary\"]=df[\"summary\"].apply(lambda x: clean_text(x))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "3ee47dff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>news</th>\n",
       "      <th>summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ad sales boost time warner profit quarterly pr...</td>\n",
       "      <td>&lt;sos&gt; timewarner said fourth quarter sales ros...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>dollar gains on greenspan speech the dollar ha...</td>\n",
       "      <td>&lt;sos&gt; the dollar has hit its highest level aga...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>yukos unit buyer faces loan claim the owners o...</td>\n",
       "      <td>&lt;sos&gt; yukos owner menatep group says it will a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>high fuel prices hit ba s profits british airw...</td>\n",
       "      <td>&lt;sos&gt; rod eddington ba s chief executive said ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>pernod takeover talk lifts domecq shares in uk...</td>\n",
       "      <td>&lt;sos&gt; pernod has reduced the debt it took on t...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                news  \\\n",
       "0  ad sales boost time warner profit quarterly pr...   \n",
       "1  dollar gains on greenspan speech the dollar ha...   \n",
       "2  yukos unit buyer faces loan claim the owners o...   \n",
       "3  high fuel prices hit ba s profits british airw...   \n",
       "4  pernod takeover talk lifts domecq shares in uk...   \n",
       "\n",
       "                                             summary  \n",
       "0  <sos> timewarner said fourth quarter sales ros...  \n",
       "1  <sos> the dollar has hit its highest level aga...  \n",
       "2  <sos> yukos owner menatep group says it will a...  \n",
       "3  <sos> rod eddington ba s chief executive said ...  \n",
       "4  <sos> pernod has reduced the debt it took on t...  "
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"summary\"]='<sos> '+df[\"summary\"]+' <eos>'\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "9a0f096c",
   "metadata": {},
   "outputs": [],
   "source": [
    "PAD = \"<pad>\"\n",
    "SOS = \"<sos>\"\n",
    "EOS = \"<eos>\"\n",
    "UNK = \"<unk>\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be3880fa",
   "metadata": {},
   "source": [
    "Ref: GPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "4f993e01",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "class Vocab:\n",
    "    def __init__(self, texts, max_size=30000, min_freq=2):\n",
    "        counter = Counter()\n",
    "        for text in texts:\n",
    "            counter.update(text.split())\n",
    "\n",
    "        self.itos = [PAD, SOS, EOS, UNK]\n",
    "        for word, freq in counter.most_common():\n",
    "            if freq >= min_freq and len(self.itos) < max_size:\n",
    "                self.itos.append(word)\n",
    "\n",
    "        self.stoi = {word: idx for idx, word in enumerate(self.itos)}\n",
    "\n",
    "    def encode(self, text):\n",
    "        return [self.stoi.get(w, self.stoi[UNK]) for w in text.split()]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.itos)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "e38733a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Article Vocab Size: 18730\n",
      "Summary Vocab Size: 12388\n"
     ]
    }
   ],
   "source": [
    "article_vocab = Vocab(df[\"news\"], max_size=30000)\n",
    "summary_vocab = Vocab(df[\"summary\"], max_size=15000)\n",
    "print(f\"Article Vocab Size: {len(article_vocab)}\")\n",
    "print(f\"Summary Vocab Size: {len(summary_vocab)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "ef1008f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset,DataLoader\n",
    "import torch\n",
    "class SummaryDataset(Dataset):\n",
    "    def __init__(self,df,article_vocab,summary_vocab,max_article_len=512,max_summary_len=50):\n",
    "        super().__init__()\n",
    "        self.df=df\n",
    "        self.article_vocab=article_vocab\n",
    "        self.summary_vocab=summary_vocab\n",
    "        self.max_article_len=max_article_len\n",
    "        self.max_summary_len=max_summary_len\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def pad(self, sequence, max_length, pad_idx):\n",
    "        return sequence[:max_length] + [pad_idx] * (max_length - len(sequence))\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        article=self.df.iloc[idx][\"news\"]\n",
    "        summary=self.df.iloc[idx][\"summary\"]\n",
    "        \n",
    "        enc=self.article_vocab.encode(article)\n",
    "        dec=self.summary_vocab.encode(summary)\n",
    "        \n",
    "        enc=self.pad(enc,self.max_article_len,self.article_vocab.stoi[PAD])\n",
    "        dec=self.pad(dec,self.max_summary_len,self.summary_vocab.stoi[PAD])\n",
    "        \n",
    "        return torch.tensor(enc), torch.tensor(dec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "57433986",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset=SummaryDataset(df,article_vocab,summary_vocab)\n",
    "loader=DataLoader(dataset,batch_size=2,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "5f5ddec6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([ 4052,   187,   700,    71,  3353,  1026,  3787,   623,    25,    51,\n",
       "           299,   694,  7877,  2857,     5,    89,    57,    11,     4,   104,\n",
       "           197,     5,   324,    31,    57,    44,   349,     4,   146,    40,\n",
       "            10,    76,    53,     6,     4,   326,   846,     9,   923,  7878,\n",
       "            31,   187,     6,   161,   803,   315,  1846,     7,   586,  5340,\n",
       "           187,  7877,    16,   627,   394,   187,   636,     5,    89,    31,\n",
       "            89,    45,   623,    47,  9466,    28,    53,   130,  2726,    40,\n",
       "          3921,     8,  1026,  3682,    25,  3353,  6344,     7,   353,   226,\n",
       "            11,  3020,    71,  3353,    16,    15,   543,    13,    14,    76,\n",
       "          2265,     6,   482,  1881,   923,    29,    45,   202,   315,   239,\n",
       "          3020,    39,    23,  2858,  4053,    14,   321,  2786,     9,     4,\n",
       "           627,   394,   623,    47,   917,    60,     9,     4, 10595,   104,\n",
       "          2787,   179,     4,   125,    16,  3020,    12,  4891,  1026,   107,\n",
       "          6345,  2508,   636,    15,     4,   102,     6,  1847,   315,  2093,\n",
       "          1654,    14,   782,     5,   386,  2786,    28,  1164,     4,   274,\n",
       "           205,   389,     5,  7877,   315,   607,     7,    24,   419,     5,\n",
       "          1213,    46,  3020,    12,  1363,   607,    11,   161,   803,   413,\n",
       "          7877,    48,    23,     5,  6346,     7,   740,   387,     8,  4054,\n",
       "            28,     4,    51,  1754,   773,   593,  2020,    40,    10,   553,\n",
       "             5, 10596,    71,  3353,    12,   627,   394,   623,    47,  1784,\n",
       "           267,    60,   362,  1536,    29,    45,    95,  1537,   587,   623,\n",
       "          4699,     5,    57,   788,    28,   677,   270, 14439,  2859,     7,\n",
       "             3,     8,  2168,  2169,     5,    44,   349,    70,     4,   233,\n",
       "             7,   250,    95,     9,     4,   370,     6,     4,  2788,  5651,\n",
       "          2615,   740,    11,     4,   414,    44,  7877,  2727,     8,  1026,\n",
       "             6,    89,    46,    31,    45,   469,   110,  1654,  1723,     5,\n",
       "            89,   127,   398,   469,    17,   373,   444,    59, 12190,    61,\n",
       "             6,   127,   414,    44,  6347,     7,  6784,  4190,   127,  3788,\n",
       "           472,     7,   203,   308,  1165, 14440,    16,    11,  7877,    10,\n",
       "         14441,  1101,  1317,   196,     6,   234,     7,    48,  1785,   586,\n",
       "          1424,     7,  2124,  1026,  4504,  7877,    10,     5,  6346,    45,\n",
       "          1134,    22,   157,     6,  1364,     5,  3922,    37,  1353,    80,\n",
       "          3020,    28,    51,   121,  3180,    14,    23,   193,   941,     5,\n",
       "           350,    57,     5,  2509,   865,     9,     8,   215,    13,    10,\n",
       "           165,  1330,    28,     4,  2020,     4,   125,    16,    14,    17,\n",
       "          2302,     5,  3021,     4,   897,    14,   500,     5,   113,  2728,\n",
       "            11,   356,  2729,    40,    14,   997,   113,    25,    57,    14,\n",
       "          4191,     5,  9467,     4,   119,    14,  1134,    11,     8,   215,\n",
       "            20,   767,   103,  4700,     3,    12,  2563,     6,     8,  1232,\n",
       "             9,  3020,   230,    40,    14,    39,   613,    22,  2093,  1424,\n",
       "            14,    24,    76,   624,     4,   440,     6,    45,  1232,     9,\n",
       "          3020,   230,    22,     8,  1166,    15,     4,   774,     6,    13,\n",
       "          1232,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0]),\n",
       " tensor([  22, 6510,   10,  506,  336,  168,  603,    5,   78,   33,   78,   11,\n",
       "            4,  378,   42, 6510, 1966,    7,  926,    6,   78,   50,   33,   43,\n",
       "          519,  104, 1743, 1379,    5,   78, 3685,  648,   25,   48,  337,  572,\n",
       "         6510, 3016,    5,   78,   57,   11,    4,   97,  199,    5,  314,   33,\n",
       "           57,   42]))"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "ae560fe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim, hidden_dim):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_dim, padding_idx=0)\n",
    "        self.lstm = nn.LSTM(embed_dim, hidden_dim, batch_first=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        emb = self.embedding(x)\n",
    "        outputs, (h, c) = self.lstm(emb)\n",
    "        return h, c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "a44805ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim, hidden_dim):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_dim, padding_idx=0)\n",
    "        self.lstm = nn.LSTM(embed_dim, hidden_dim, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_dim, vocab_size)\n",
    "\n",
    "    def forward(self, x, h, c):\n",
    "        x = x.unsqueeze(1) # Add sequence dimension\n",
    "        emb = self.embedding(x)\n",
    "        output, (h, c) = self.lstm(emb, (h, c))\n",
    "        pred = self.fc(output.squeeze(1))\n",
    "        return pred, h, c\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "882c0bf7",
   "metadata": {},
   "source": [
    "`x = x.unsqueeze(1)`\n",
    "\n",
    "Why?\n",
    "\n",
    "PyTorch LSTM expects:\n",
    "- (batch, seq_len, features)\n",
    "\n",
    "But x is:\n",
    "- (batch,)\n",
    "\n",
    "So we add a fake time dimension:\n",
    "- (batch, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "95beb0e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SeqtoSeqModel(nn.Module):\n",
    "    def __init__(self, encoder_model ,decoder_model , computation_device):\n",
    "        super(SeqtoSeqModel, self).__init__()\n",
    "        \n",
    "        self.encoder_model  = encoder_model\n",
    "        self.decoder_model = decoder_model\n",
    "        self.device = computation_device\n",
    "        \n",
    "    def forward(self, enc_in_seq, dec_in_seq, teacher_forcing_ratio=0.5):\n",
    "        batch_size, decoder_sequence_length = dec_in_seq.shape\n",
    "        decoder_vocabulary_size = self.decoder_model.fc.out_features\n",
    "        \n",
    "        all_decoder_outputs = torch.zeros(batch_size, decoder_sequence_length, decoder_vocabulary_size, device=self.device)\n",
    "        \n",
    "        encoder_hidden, encoder_cell = self.encoder_model(enc_in_seq)\n",
    "        current_decoder_input_token = dec_in_seq[:, 0]  # the <sos> token\n",
    "        \n",
    "        for time_stamp in range(decoder_sequence_length):\n",
    "            predicted_token_logits, encoder_hidden, encoder_cell = self.decoder_model(current_decoder_input_token, encoder_hidden, encoder_cell)\n",
    "            all_decoder_outputs[:, time_stamp, :] = predicted_token_logits\n",
    "            use_teacher_forcing = (torch.rand(1).item() < teacher_forcing_ratio) and (time_stamp + 1 < decoder_sequence_length)\n",
    "            if use_teacher_forcing:\n",
    "                current_decoder_input_token = dec_in_seq[:, time_stamp + 1]\n",
    "            else:\n",
    "                current_decoder_input_token = predicted_token_logits.argmax(dim=1)\n",
    "        return all_decoder_outputs\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "99f4a775",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "embed_dim = 256\n",
    "hidden_dim = 512\n",
    "\n",
    "encoder = Encoder(len(article_vocab), embed_dim, hidden_dim)\n",
    "decoder = Decoder(len(summary_vocab), embed_dim, hidden_dim)\n",
    "\n",
    "sequence_to_sequence_model = SeqtoSeqModel(encoder, decoder, device).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "7898f53e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pad_idx = summary_vocab.stoi[PAD]\n",
    "loss_function = nn.CrossEntropyLoss(ignore_index=pad_idx)\n",
    "optimizer = torch.optim.Adam(\n",
    "    sequence_to_sequence_model.parameters(),\n",
    "    lr=0.001\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ed909dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.utils import clip_grad_norm_\n",
    "from tqdm import tqdm\n",
    "\n",
    "num_epochs = 20\n",
    "teacher_forcing_ratio = 0.6\n",
    "\n",
    "sequence_to_sequence_model.train()\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    epoch_loss = 0.0\n",
    "    for enc_batch, dec_batch in tqdm(loader, desc=f\"Epoch {epoch+1}/{num_epochs}\"):\n",
    "        enc_batch = enc_batch.to(device)\n",
    "        dec_batch = dec_batch.to(device)\n",
    "\n",
    "        dec_input = dec_batch[:, :-1]\n",
    "        targets = dec_batch[:, 1:]\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = sequence_to_sequence_model(enc_batch, dec_input, teacher_forcing_ratio=teacher_forcing_ratio)\n",
    "        outputs = outputs.reshape(-1, outputs.size(-1))\n",
    "        targets = targets.reshape(-1)\n",
    "\n",
    "        loss = loss_function(outputs, targets)\n",
    "        loss.backward()\n",
    "        clip_grad_norm_(sequence_to_sequence_model.parameters(), 1.0)\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "    avg_loss = epoch_loss / len(loader)\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs} - Loss: {avg_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "254771cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_text(model, article, article_vocab, summary_vocab, device, max_summary_len=50):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        enc_input = torch.tensor(article_vocab.encode(article)).unsqueeze(0).to(device)\n",
    "        encoder_hidden, encoder_cell = model.encoder_model(enc_input)\n",
    "\n",
    "        current_decoder_input_token = torch.tensor([summary_vocab.stoi[SOS]]).to(device)\n",
    "        summary_tokens = []\n",
    "\n",
    "        for _ in range(max_summary_len):\n",
    "            predicted_token_logits, encoder_hidden, encoder_cell = model.decoder_model(current_decoder_input_token, encoder_hidden, encoder_cell)\n",
    "            predicted_token_id = predicted_token_logits.argmax(dim=1).item()\n",
    "            if predicted_token_id == summary_vocab.stoi[EOS]:\n",
    "                break\n",
    "            summary_tokens.append(predicted_token_id)\n",
    "            current_decoder_input_token = torch.tensor([predicted_token_id]).to(device)\n",
    "\n",
    "        summary_words = [summary_vocab.itos[token_id] for token_id in summary_tokens]\n",
    "        return ' '.join(summary_words)\n",
    "\n",
    "def summarize_text_beam_search(model, article, article_vocab, summary_vocab, device, max_summary_len=50, beam_width=3):\n",
    "    \"\"\"Beam search with repetition penalty and length normalization\"\"\"\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        enc_input = torch.tensor(article_vocab.encode(article)).unsqueeze(0).to(device)\n",
    "        encoder_hidden, encoder_cell = model.encoder_model(enc_input)\n",
    "        \n",
    "        # Initialize beams: (log_prob, tokens, hidden, cell, is_finished)\n",
    "        beams = [(0.0, [summary_vocab.stoi[SOS]], encoder_hidden, encoder_cell, False)]\n",
    "        finished_beams = []\n",
    "        \n",
    "        for step in range(max_summary_len):\n",
    "            new_beams = []\n",
    "            \n",
    "            for log_prob, tokens, h, c, is_finished in beams:\n",
    "                if is_finished:\n",
    "                    finished_beams.append((log_prob, tokens))\n",
    "                    continue\n",
    "                    \n",
    "                current_token = torch.tensor([tokens[-1]]).to(device)\n",
    "                logits, h_new, c_new = model.decoder_model(current_token, h, c)\n",
    "                log_probs = torch.log_softmax(logits, dim=1)[0]\n",
    "                \n",
    "                # Repetition penalty: penalize tokens that appear frequently in the sequence\n",
    "                for token_id in set(tokens[1:]):  # Skip SOS token\n",
    "                    count = tokens[1:].count(token_id)\n",
    "                    if count > 2:\n",
    "                        log_probs[token_id] -= 1.0 * (count - 1)  # Penalty increases with frequency\n",
    "                \n",
    "                # Block PAD token\n",
    "                log_probs[summary_vocab.stoi[PAD]] = float('-inf')\n",
    "                \n",
    "                # Get top-k candidates\n",
    "                top_k = torch.topk(log_probs, min(beam_width, log_probs.numel()), largest=True)\n",
    "                \n",
    "                for candidate_log_prob, candidate_id in zip(top_k.values, top_k.indices):\n",
    "                    if torch.isinf(candidate_log_prob):\n",
    "                        continue\n",
    "                    new_log_prob = log_prob + candidate_log_prob.item()\n",
    "                    new_tokens = tokens + [candidate_id.item()]\n",
    "                    is_eos = (candidate_id.item() == summary_vocab.stoi[EOS])\n",
    "                    \n",
    "                    new_beams.append((new_log_prob, new_tokens, h_new, c_new, is_eos))\n",
    "            \n",
    "            # Sort by normalized log probability (length penalty)\n",
    "            new_beams.sort(reverse=True, key=lambda x: x[0] / max(len(x[1]), 1) ** 0.7)\n",
    "            beams = new_beams[:beam_width]\n",
    "            \n",
    "            # Separate finished and unfinished beams\n",
    "            finished_beams.extend([b for b in beams if b[4]])\n",
    "            beams = [b for b in beams if not b[4]]\n",
    "            \n",
    "            if not beams:\n",
    "                break\n",
    "        \n",
    "        # Combine and sort all beams\n",
    "        all_beams = finished_beams + beams\n",
    "        all_beams.sort(reverse=True, key=lambda x: x[0] / max(len(x[1]), 1) ** 0.7)\n",
    "        \n",
    "        # Return best beam\n",
    "        if all_beams:\n",
    "            best_tokens = all_beams[0][1][1:]  # Remove SOS token\n",
    "            summary_words = [summary_vocab.itos[token_id] for token_id in best_tokens if token_id != summary_vocab.stoi[EOS]]\n",
    "            return ' '.join(summary_words)\n",
    "        return \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fe0703c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Greedy Decoding:\")\n",
    "print(summarize_text(sequence_to_sequence_model, df.iloc[0][\"news\"], article_vocab, summary_vocab, device))\n",
    "\n",
    "print(\"\\nBeam Search Decoding (beam_width=3):\")\n",
    "print(summarize_text_beam_search(sequence_to_sequence_model, df.iloc[0][\"news\"], article_vocab, summary_vocab, device, beam_width=3))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
