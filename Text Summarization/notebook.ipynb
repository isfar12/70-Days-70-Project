{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "43f955cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import T5Tokenizer, T5ForConditionalGeneration, T5Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "01897cec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install sentencepiece"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5f4cdf6",
   "metadata": {},
   "source": [
    "# Option 1: Using T5 Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ee7e5cb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n"
     ]
    }
   ],
   "source": [
    "#initialize the model and tokenizer\n",
    "model_name = 't5-small'\n",
    "tokenizer = T5Tokenizer.from_pretrained(model_name)\n",
    "config = T5Config.from_pretrained(model_name)\n",
    "model = T5ForConditionalGeneration.from_pretrained(model_name, config=config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e006bb5f",
   "metadata": {},
   "source": [
    "T5 models expect the input text to be prefixed with a task-specific prompt, such as \"summarize: \" for summarization tasks. This helps the model understand what kind of output is expected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "721fbd83",
   "metadata": {},
   "outputs": [],
   "source": [
    "text=\"\"\"We all know that OpenAI actually started the trend of AI tools after releasing ChatGPT.\n",
    "After that, we saw everyone shift to AI. Developers and big companies began building AI tools, and even individuals started learning about artificial intelligence.\n",
    "Thanks to that, we have tons of popular AI tools like RunwayML, Lovable, Claude, Gemini, Perplexity, Cursor, Stitch, NotebookLM, Leonardo AI, Framer AI, and the list goes on.\n",
    "That's not all. Every day, tons of new AI tools are launched, which makes it difficult for people to find the best ones for their needs.\n",
    "That's why I spend a lot of time testing some of the best new AI tools and write a couple of posts every month to share the ones that truly stand out.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "16fddf93",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import html\n",
    "# modified with GPT for best practices\n",
    "def clean_text(text):\n",
    "    text = html.unescape(text)\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'<.*?>', ' ', text)             # remove HTML\n",
    "    text = re.sub(r'http\\S+|www\\.\\S+', ' ', text)  # remove URLs\n",
    "    text = re.sub(r'\\S+@\\S+', ' ', text)           # remove emails\n",
    "    text = re.sub(r\"(.)\\1{2,}\", r\"\\1\\1\", text)     # soooo -> soo\n",
    "\n",
    "    # keep ! and ? (sentiment)\n",
    "    text = re.sub(r'[^a-z!? ]', ' ', text)\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "60dffac2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "127"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_text=clean_text(text).split()\n",
    "len(cleaned_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "af12d5dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[21603,    10,    62,    66,   214,    24,   539,     9,    23,   700,\n",
      "           708,     8,  4166,    13,     3,     9,    23,  1339,   227,     3,\n",
      "         16306,  3582,   122,   102,    17,   227,    24,    62,  1509,   921,\n",
      "          4108,    12,     3,     9,    23,  5564,    11,   600,   688,  1553,\n",
      "           740,     3,     9,    23,  1339,    11,   237,  1742,   708,  1036,\n",
      "            81,  7353,  6123,  2049,    12,    24,    62,    43,  8760,    13,\n",
      "          1012,     3,     9,    23,  1339,   114, 22750,    51,    40,     3,\n",
      "          5850,   179,     3,    75, 12513,    15,   873,  7619,   399,  9247,\n",
      "           485,  8385,   127, 12261, 16638,    40,    51,    90,   106,   986,\n",
      "            32,     3,     9,    23,  2835,    52,     3,     9,    23,    11,\n",
      "             8,   570,  1550,    30,    24,     3,     7,    59,    66,   334,\n",
      "           239,  8760,    13,   126,     3,     9,    23,  1339,    33,  3759,\n",
      "            84,   656,    34,  1256,    21,   151,    12,   253,     8,   200,\n",
      "          2102,    21,    70,   523,    24,     3,     7,   572,     3,    23,\n",
      "          1492,     3,     9,   418,    13,    97,  2505,   128,    13,     8,\n",
      "           200,   126,     3,     9,    23,  1339,    11,  1431,     3,     9,\n",
      "          1158,    13,  3489,   334,   847,    12,   698,     8,  2102,    24,\n",
      "          1892,  1518,    91,     1]])\n"
     ]
    }
   ],
   "source": [
    "tokenized_text=tokenizer.encode(\"summarize: \" + clean_text(text), return_tensors=\"pt\", max_length=512, truncation=True)\n",
    "print(tokenized_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "0ef34c0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary:\n",
      "openai has tons of popular ai tools like runwayml lovable claude gemini perplexity cursor stitch notebooklm leonardo ai framer ai. the list goes on that s not all every day tons of new ai tools are launched which makes it difficult for people to find the best ones for their needs.\n",
      "51\n"
     ]
    }
   ],
   "source": [
    "summary_ids=model.generate(tokenized_text, max_length=150, min_length=40, length_penalty=2.0, num_beams=4, early_stopping=True)\n",
    "summary=tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
    "\n",
    "print(\"Summary:\")\n",
    "print(summary)\n",
    "print(len(summary.split()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1860326",
   "metadata": {},
   "source": [
    "# Option 2 : Using Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "75e531e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\LENOVO\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'summary_text': \"Every day, tons of new AI tools are launched, which makes it difficult for people to find the best ones for their needs. That's why I spend a lot of time testing some of the best newAI tools and write a couple of posts every month to share the ones that truly stand out.\"}]\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "summarizer = pipeline(\"summarization\", model=\"facebook/bart-large-cnn\")\n",
    "summary = summarizer(text, max_length=130, min_length=30)\n",
    "\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e82490ec",
   "metadata": {},
   "source": [
    "# Option 3: LSTM/GRU/RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "f0b23635",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['business', 'entertainment', 'politics', 'sport', 'tech'],\n",
       " ['business', 'entertainment', 'politics', 'sport', 'tech'])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from glob import glob\n",
    "from pathlib import Path\n",
    "\n",
    "news_files = Path(\"E:\\\\70 Days 70 Project\\\\Text Summarization\\\\data\\\\BBC News Summary\\\\News Articles\")\n",
    "summaries_files = Path(\"E:\\\\70 Days 70 Project\\\\Text Summarization\\\\data\\\\BBC News Summary\\\\Summaries\")\n",
    "\n",
    "news_categories=os.listdir(news_files)\n",
    "summary_categories=os.listdir(summaries_files)\n",
    "news_categories,summary_categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "483040d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "001.txt\n",
      "002.txt\n",
      "003.txt\n",
      "004.txt\n",
      "005.txt\n",
      "006.txt\n",
      "007.txt\n",
      "008.txt\n",
      "009.txt\n",
      "010.txt\n",
      "011.txt\n",
      "012.txt\n",
      "013.txt\n",
      "014.txt\n",
      "015.txt\n",
      "016.txt\n",
      "017.txt\n",
      "018.txt\n",
      "019.txt\n",
      "020.txt\n",
      "021.txt\n",
      "022.txt\n",
      "023.txt\n",
      "024.txt\n",
      "025.txt\n",
      "026.txt\n",
      "027.txt\n",
      "028.txt\n",
      "029.txt\n",
      "030.txt\n",
      "031.txt\n",
      "032.txt\n",
      "033.txt\n",
      "034.txt\n",
      "035.txt\n",
      "036.txt\n",
      "037.txt\n",
      "038.txt\n",
      "039.txt\n",
      "040.txt\n",
      "041.txt\n",
      "042.txt\n",
      "043.txt\n",
      "044.txt\n",
      "045.txt\n",
      "046.txt\n",
      "047.txt\n",
      "048.txt\n",
      "049.txt\n",
      "050.txt\n",
      "051.txt\n",
      "052.txt\n",
      "053.txt\n",
      "054.txt\n",
      "055.txt\n",
      "056.txt\n",
      "057.txt\n",
      "058.txt\n",
      "059.txt\n",
      "060.txt\n",
      "061.txt\n",
      "062.txt\n",
      "063.txt\n",
      "064.txt\n",
      "065.txt\n",
      "066.txt\n",
      "067.txt\n",
      "068.txt\n",
      "069.txt\n",
      "070.txt\n",
      "071.txt\n",
      "072.txt\n",
      "073.txt\n",
      "074.txt\n",
      "075.txt\n",
      "076.txt\n",
      "077.txt\n",
      "078.txt\n",
      "079.txt\n",
      "080.txt\n",
      "081.txt\n",
      "082.txt\n",
      "083.txt\n",
      "084.txt\n",
      "085.txt\n",
      "086.txt\n",
      "087.txt\n",
      "088.txt\n",
      "089.txt\n",
      "090.txt\n",
      "091.txt\n",
      "092.txt\n",
      "093.txt\n",
      "094.txt\n",
      "095.txt\n",
      "096.txt\n",
      "097.txt\n",
      "098.txt\n",
      "099.txt\n",
      "100.txt\n",
      "101.txt\n",
      "102.txt\n",
      "103.txt\n",
      "104.txt\n",
      "105.txt\n",
      "106.txt\n",
      "107.txt\n",
      "108.txt\n",
      "109.txt\n",
      "110.txt\n",
      "111.txt\n",
      "112.txt\n",
      "113.txt\n",
      "114.txt\n",
      "115.txt\n",
      "116.txt\n",
      "117.txt\n",
      "118.txt\n",
      "119.txt\n",
      "120.txt\n",
      "121.txt\n",
      "122.txt\n",
      "123.txt\n",
      "124.txt\n",
      "125.txt\n",
      "126.txt\n",
      "127.txt\n",
      "128.txt\n",
      "129.txt\n",
      "130.txt\n",
      "131.txt\n",
      "132.txt\n",
      "133.txt\n",
      "134.txt\n",
      "135.txt\n",
      "136.txt\n",
      "137.txt\n",
      "138.txt\n",
      "139.txt\n",
      "140.txt\n",
      "141.txt\n",
      "142.txt\n",
      "143.txt\n",
      "144.txt\n",
      "145.txt\n",
      "146.txt\n",
      "147.txt\n",
      "148.txt\n",
      "149.txt\n",
      "150.txt\n",
      "151.txt\n",
      "152.txt\n",
      "153.txt\n",
      "154.txt\n",
      "155.txt\n",
      "156.txt\n",
      "157.txt\n",
      "158.txt\n",
      "159.txt\n",
      "160.txt\n",
      "161.txt\n",
      "162.txt\n",
      "163.txt\n",
      "164.txt\n",
      "165.txt\n",
      "166.txt\n",
      "167.txt\n",
      "168.txt\n",
      "169.txt\n",
      "170.txt\n",
      "171.txt\n",
      "172.txt\n",
      "173.txt\n",
      "174.txt\n",
      "175.txt\n",
      "176.txt\n",
      "177.txt\n",
      "178.txt\n",
      "179.txt\n",
      "180.txt\n",
      "181.txt\n",
      "182.txt\n",
      "183.txt\n",
      "184.txt\n",
      "185.txt\n",
      "186.txt\n",
      "187.txt\n",
      "188.txt\n",
      "189.txt\n",
      "190.txt\n",
      "191.txt\n",
      "192.txt\n",
      "193.txt\n",
      "194.txt\n",
      "195.txt\n",
      "196.txt\n",
      "197.txt\n",
      "198.txt\n",
      "199.txt\n",
      "200.txt\n",
      "201.txt\n",
      "202.txt\n",
      "203.txt\n",
      "204.txt\n",
      "205.txt\n",
      "206.txt\n",
      "207.txt\n",
      "208.txt\n",
      "209.txt\n",
      "210.txt\n",
      "211.txt\n",
      "212.txt\n",
      "213.txt\n",
      "214.txt\n",
      "215.txt\n",
      "216.txt\n",
      "217.txt\n",
      "218.txt\n",
      "219.txt\n",
      "220.txt\n",
      "221.txt\n",
      "222.txt\n",
      "223.txt\n",
      "224.txt\n",
      "225.txt\n",
      "226.txt\n",
      "227.txt\n",
      "228.txt\n",
      "229.txt\n",
      "230.txt\n",
      "231.txt\n",
      "232.txt\n",
      "233.txt\n",
      "234.txt\n",
      "235.txt\n",
      "236.txt\n",
      "237.txt\n",
      "238.txt\n",
      "239.txt\n",
      "240.txt\n",
      "241.txt\n",
      "242.txt\n",
      "243.txt\n",
      "244.txt\n",
      "245.txt\n",
      "246.txt\n",
      "247.txt\n",
      "248.txt\n",
      "249.txt\n",
      "250.txt\n",
      "251.txt\n",
      "252.txt\n",
      "253.txt\n",
      "254.txt\n",
      "255.txt\n",
      "256.txt\n",
      "257.txt\n",
      "258.txt\n",
      "259.txt\n",
      "260.txt\n",
      "261.txt\n",
      "262.txt\n",
      "263.txt\n",
      "264.txt\n",
      "265.txt\n",
      "266.txt\n",
      "267.txt\n",
      "268.txt\n",
      "269.txt\n",
      "270.txt\n",
      "271.txt\n",
      "272.txt\n",
      "273.txt\n",
      "274.txt\n",
      "275.txt\n",
      "276.txt\n",
      "277.txt\n",
      "278.txt\n",
      "279.txt\n",
      "280.txt\n",
      "281.txt\n",
      "282.txt\n",
      "283.txt\n",
      "284.txt\n",
      "285.txt\n",
      "286.txt\n",
      "287.txt\n",
      "288.txt\n",
      "289.txt\n",
      "290.txt\n",
      "291.txt\n",
      "292.txt\n",
      "293.txt\n",
      "294.txt\n",
      "295.txt\n",
      "296.txt\n",
      "297.txt\n",
      "298.txt\n",
      "299.txt\n",
      "300.txt\n",
      "301.txt\n",
      "302.txt\n",
      "303.txt\n",
      "304.txt\n",
      "305.txt\n",
      "306.txt\n",
      "307.txt\n",
      "308.txt\n",
      "309.txt\n",
      "310.txt\n",
      "311.txt\n",
      "312.txt\n",
      "313.txt\n",
      "314.txt\n",
      "315.txt\n",
      "316.txt\n",
      "317.txt\n",
      "318.txt\n",
      "319.txt\n",
      "320.txt\n",
      "321.txt\n",
      "322.txt\n",
      "323.txt\n",
      "324.txt\n",
      "325.txt\n",
      "326.txt\n",
      "327.txt\n",
      "328.txt\n",
      "329.txt\n",
      "330.txt\n",
      "331.txt\n",
      "332.txt\n",
      "333.txt\n",
      "334.txt\n",
      "335.txt\n",
      "336.txt\n",
      "337.txt\n",
      "338.txt\n",
      "339.txt\n",
      "340.txt\n",
      "341.txt\n",
      "342.txt\n",
      "343.txt\n",
      "344.txt\n",
      "345.txt\n",
      "346.txt\n",
      "347.txt\n",
      "348.txt\n",
      "349.txt\n",
      "350.txt\n",
      "351.txt\n",
      "352.txt\n",
      "353.txt\n",
      "354.txt\n",
      "355.txt\n",
      "356.txt\n",
      "357.txt\n",
      "358.txt\n",
      "359.txt\n",
      "360.txt\n",
      "361.txt\n",
      "362.txt\n",
      "363.txt\n",
      "364.txt\n",
      "365.txt\n",
      "366.txt\n",
      "367.txt\n",
      "368.txt\n",
      "369.txt\n",
      "370.txt\n",
      "371.txt\n",
      "372.txt\n",
      "373.txt\n",
      "374.txt\n",
      "375.txt\n",
      "376.txt\n",
      "377.txt\n",
      "378.txt\n",
      "379.txt\n",
      "380.txt\n",
      "381.txt\n",
      "382.txt\n",
      "383.txt\n",
      "384.txt\n",
      "385.txt\n",
      "386.txt\n",
      "387.txt\n",
      "388.txt\n",
      "389.txt\n",
      "390.txt\n",
      "391.txt\n",
      "392.txt\n",
      "393.txt\n",
      "394.txt\n",
      "395.txt\n",
      "396.txt\n",
      "397.txt\n",
      "398.txt\n",
      "399.txt\n",
      "400.txt\n",
      "401.txt\n",
      "402.txt\n",
      "403.txt\n",
      "404.txt\n",
      "405.txt\n",
      "406.txt\n",
      "407.txt\n",
      "408.txt\n",
      "409.txt\n",
      "410.txt\n",
      "411.txt\n",
      "412.txt\n",
      "413.txt\n",
      "414.txt\n",
      "415.txt\n",
      "416.txt\n",
      "417.txt\n",
      "418.txt\n",
      "419.txt\n",
      "420.txt\n",
      "421.txt\n",
      "422.txt\n",
      "423.txt\n",
      "424.txt\n",
      "425.txt\n",
      "426.txt\n",
      "427.txt\n",
      "428.txt\n",
      "429.txt\n",
      "430.txt\n",
      "431.txt\n",
      "432.txt\n",
      "433.txt\n",
      "434.txt\n",
      "435.txt\n",
      "436.txt\n",
      "437.txt\n",
      "438.txt\n",
      "439.txt\n",
      "440.txt\n",
      "441.txt\n",
      "442.txt\n",
      "443.txt\n",
      "444.txt\n",
      "445.txt\n",
      "446.txt\n",
      "447.txt\n",
      "448.txt\n",
      "449.txt\n",
      "450.txt\n",
      "451.txt\n",
      "452.txt\n",
      "453.txt\n",
      "454.txt\n",
      "455.txt\n",
      "456.txt\n",
      "457.txt\n",
      "458.txt\n",
      "459.txt\n",
      "460.txt\n",
      "461.txt\n",
      "462.txt\n",
      "463.txt\n",
      "464.txt\n",
      "465.txt\n",
      "466.txt\n",
      "467.txt\n",
      "468.txt\n",
      "469.txt\n",
      "470.txt\n",
      "471.txt\n",
      "472.txt\n",
      "473.txt\n",
      "474.txt\n",
      "475.txt\n",
      "476.txt\n",
      "477.txt\n",
      "478.txt\n",
      "479.txt\n",
      "480.txt\n",
      "481.txt\n",
      "482.txt\n",
      "483.txt\n",
      "484.txt\n",
      "485.txt\n",
      "486.txt\n",
      "487.txt\n",
      "488.txt\n",
      "489.txt\n",
      "490.txt\n",
      "491.txt\n",
      "492.txt\n",
      "493.txt\n",
      "494.txt\n",
      "495.txt\n",
      "496.txt\n",
      "497.txt\n",
      "498.txt\n",
      "499.txt\n",
      "500.txt\n",
      "501.txt\n",
      "502.txt\n",
      "503.txt\n",
      "504.txt\n",
      "505.txt\n",
      "506.txt\n",
      "507.txt\n",
      "508.txt\n",
      "509.txt\n",
      "510.txt\n"
     ]
    }
   ],
   "source": [
    "for files in os.listdir(Path(news_files/news_categories[0])):\n",
    "    print(files)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b96c2f9a",
   "metadata": {},
   "source": [
    "Ref: https://www.kaggle.com/code/mallaavinash/text-summarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ba2cc21f",
   "metadata": {},
   "outputs": [],
   "source": [
    "contraction_mapping = {\"ain't\": \"is not\", \"aren't\": \"are not\",\"can't\": \"cannot\", \"'cause\": \"because\", \"could've\": \"could have\", \"couldn't\": \"could not\",\n",
    "\n",
    "                           \"didn't\": \"did not\", \"doesn't\": \"does not\", \"don't\": \"do not\", \"hadn't\": \"had not\", \"hasn't\": \"has not\", \"haven't\": \"have not\",\n",
    "\n",
    "                           \"he'd\": \"he would\",\"he'll\": \"he will\", \"he's\": \"he is\", \"how'd\": \"how did\", \"how'd'y\": \"how do you\", \"how'll\": \"how will\", \"how's\": \"how is\",\n",
    "\n",
    "                           \"I'd\": \"I would\", \"I'd've\": \"I would have\", \"I'll\": \"I will\", \"I'll've\": \"I will have\",\"I'm\": \"I am\", \"I've\": \"I have\", \"i'd\": \"i would\",\n",
    "\n",
    "                           \"i'd've\": \"i would have\", \"i'll\": \"i will\",  \"i'll've\": \"i will have\",\"i'm\": \"i am\", \"i've\": \"i have\", \"isn't\": \"is not\", \"it'd\": \"it would\",\n",
    "\n",
    "                           \"it'd've\": \"it would have\", \"it'll\": \"it will\", \"it'll've\": \"it will have\",\"it's\": \"it is\", \"let's\": \"let us\", \"ma'am\": \"madam\",\n",
    "\n",
    "                           \"mayn't\": \"may not\", \"might've\": \"might have\",\"mightn't\": \"might not\",\"mightn't've\": \"might not have\", \"must've\": \"must have\",\n",
    "                            \"mustn't\": \"must not\", \"mustn't've\": \"must not have\", \"needn't\": \"need not\", \"needn't've\": \"need not have\",\"o'clock\": \"of the clock\",\n",
    "\n",
    "                           \"oughtn't\": \"ought not\", \"oughtn't've\": \"ought not have\", \"shan't\": \"shall not\", \"sha'n't\": \"shall not\", \"shan't've\": \"shall not have\",\n",
    "\n",
    "                           \"she'd\": \"she would\", \"she'd've\": \"she would have\", \"she'll\": \"she will\", \"she'll've\": \"she will have\", \"she's\": \"she is\",\n",
    "\n",
    "                           \"should've\": \"should have\", \"shouldn't\": \"should not\", \"shouldn't've\": \"should not have\", \"so've\": \"so have\",\"so's\": \"so as\",\n",
    "\n",
    "                           \"this's\": \"this is\",\"that'd\": \"that would\", \"that'd've\": \"that would have\", \"that's\": \"that is\", \"there'd\": \"there would\",\n",
    "\n",
    "                           \"there'd've\": \"there would have\", \"there's\": \"there is\", \"here's\": \"here is\",\"they'd\": \"they would\", \"they'd've\": \"they would have\",\n",
    "                           \"they'll\": \"they will\", \"they'll've\": \"they will have\", \"they're\": \"they are\", \"they've\": \"they have\", \"to've\": \"to have\",\n",
    "\n",
    "                           \"wasn't\": \"was not\", \"we'd\": \"we would\", \"we'd've\": \"we would have\", \"we'll\": \"we will\", \"we'll've\": \"we will have\", \"we're\": \"we are\",\n",
    "\n",
    "                           \"we've\": \"we have\", \"weren't\": \"were not\", \"what'll\": \"what will\", \"what'll've\": \"what will have\", \"what're\": \"what are\",\n",
    "\n",
    "                           \"what's\": \"what is\", \"what've\": \"what have\", \"when's\": \"when is\", \"when've\": \"when have\", \"where'd\": \"where did\", \"where's\": \"where is\",\n",
    "\n",
    "                           \"where've\": \"where have\", \"who'll\": \"who will\", \"who'll've\": \"who will have\", \"who's\": \"who is\", \"who've\": \"who have\",\n",
    "\n",
    "                           \"why's\": \"why is\", \"why've\": \"why have\", \"will've\": \"will have\", \"won't\": \"will not\", \"won't've\": \"will not have\",\n",
    "\n",
    "                           \"would've\": \"would have\", \"wouldn't\": \"would not\", \"wouldn't've\": \"would not have\", \"y'all\": \"you all\",\n",
    "                           \"y'all'd\": \"you all would\",\"y'all'd've\": \"you all would have\",\"y'all're\": \"you all are\",\"y'all've\": \"you all have\",\n",
    "\n",
    "                           \"you'd\": \"you would\", \"you'd've\": \"you would have\", \"you'll\": \"you will\", \"you'll've\": \"you will have\",\n",
    "\n",
    "                           \"you're\": \"you are\", \"you've\": \"you have\"}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "97254065",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import html\n",
    "# modified with GPT for best practices\n",
    "def clean_text(text):\n",
    "    text = html.unescape(text)\n",
    "    text = text.lower()\n",
    "    text=' '.join([contraction_mapping[i] if i in contraction_mapping.keys() else i for i in text.split()])\n",
    "    text = re.sub(r'<.*?>', ' ', text)             # remove HTML\n",
    "    text = re.sub(r'http\\S+|www\\.\\S+', ' ', text)  # remove URLs\n",
    "    text = re.sub(r'\\S+@\\S+', ' ', text)           # remove emails\n",
    "    text = re.sub(r\"(.)\\1{2,}\", r\"\\1\\1\", text)     # soooo -> soo\n",
    "\n",
    "    # keep ! and ? (sentiment)\n",
    "    text = re.sub(r'[^a-z!? ]', ' ', text)\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0158e3c",
   "metadata": {},
   "source": [
    "#### Run once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e0c50ee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# from tqdm import tqdm\n",
    "\n",
    "# dataframe={'news':[], 'summary':[]}\n",
    "\n",
    "# for category in news_categories:\n",
    "#     for file in tqdm(os.listdir(Path(news_files/category)),desc=f\"News Category: {category}\"):\n",
    "#         with open(Path(news_files/category/file), 'r', encoding='utf-8', errors='replace') as news_file:\n",
    "#             news_content=news_file.read()\n",
    "#             dataframe['news'].append(news_content)\n",
    "#     for file in tqdm(os.listdir(Path(summaries_files/category)),desc=f\"Summary Category: {category}\"):\n",
    "#         with open(Path(summaries_files/category/file), 'r', encoding='utf-8', errors='replace') as summary_file:\n",
    "#             summary_content=summary_file.read()\n",
    "#             dataframe['summary'].append(summary_content)\n",
    "# df=pd.DataFrame(dataframe)\n",
    "# df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c93dce6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fe85432c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.to_csv(\"bbc_news_summary_dataset.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a17743ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>news</th>\n",
       "      <th>summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ad sales boost Time Warner profit\\n\\nQuarterly...</td>\n",
       "      <td>TimeWarner said fourth quarter sales rose 2% t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Dollar gains on Greenspan speech\\n\\nThe dollar...</td>\n",
       "      <td>The dollar has hit its highest level against t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Yukos unit buyer faces loan claim\\n\\nThe owner...</td>\n",
       "      <td>Yukos' owner Menatep Group says it will ask Ro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>High fuel prices hit BA's profits\\n\\nBritish A...</td>\n",
       "      <td>Rod Eddington, BA's chief executive, said the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Pernod takeover talk lifts Domecq\\n\\nShares in...</td>\n",
       "      <td>Pernod has reduced the debt it took on to fund...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                news  \\\n",
       "0  Ad sales boost Time Warner profit\\n\\nQuarterly...   \n",
       "1  Dollar gains on Greenspan speech\\n\\nThe dollar...   \n",
       "2  Yukos unit buyer faces loan claim\\n\\nThe owner...   \n",
       "3  High fuel prices hit BA's profits\\n\\nBritish A...   \n",
       "4  Pernod takeover talk lifts Domecq\\n\\nShares in...   \n",
       "\n",
       "                                             summary  \n",
       "0  TimeWarner said fourth quarter sales rose 2% t...  \n",
       "1  The dollar has hit its highest level against t...  \n",
       "2  Yukos' owner Menatep Group says it will ask Ro...  \n",
       "3  Rod Eddington, BA's chief executive, said the ...  \n",
       "4  Pernod has reduced the debt it took on to fund...  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df=pd.read_csv(\"bbc_news_summary_dataset.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "857d9ae7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>news</th>\n",
       "      <th>summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ad sales boost time warner profit quarterly pr...</td>\n",
       "      <td>timewarner said fourth quarter sales rose to b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>dollar gains on greenspan speech the dollar ha...</td>\n",
       "      <td>the dollar has hit its highest level against t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>yukos unit buyer faces loan claim the owners o...</td>\n",
       "      <td>yukos owner menatep group says it will ask ros...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>high fuel prices hit ba s profits british airw...</td>\n",
       "      <td>rod eddington ba s chief executive said the re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>pernod takeover talk lifts domecq shares in uk...</td>\n",
       "      <td>pernod has reduced the debt it took on to fund...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                news  \\\n",
       "0  ad sales boost time warner profit quarterly pr...   \n",
       "1  dollar gains on greenspan speech the dollar ha...   \n",
       "2  yukos unit buyer faces loan claim the owners o...   \n",
       "3  high fuel prices hit ba s profits british airw...   \n",
       "4  pernod takeover talk lifts domecq shares in uk...   \n",
       "\n",
       "                                             summary  \n",
       "0  timewarner said fourth quarter sales rose to b...  \n",
       "1  the dollar has hit its highest level against t...  \n",
       "2  yukos owner menatep group says it will ask ros...  \n",
       "3  rod eddington ba s chief executive said the re...  \n",
       "4  pernod has reduced the debt it took on to fund...  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"news\"]=df[\"news\"].apply(lambda x: clean_text(x))\n",
    "df[\"summary\"]=df[\"summary\"].apply(lambda x: clean_text(x))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3ee47dff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>news</th>\n",
       "      <th>summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ad sales boost time warner profit quarterly pr...</td>\n",
       "      <td>&lt;sos&gt; timewarner said fourth quarter sales ros...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>dollar gains on greenspan speech the dollar ha...</td>\n",
       "      <td>&lt;sos&gt; the dollar has hit its highest level aga...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>yukos unit buyer faces loan claim the owners o...</td>\n",
       "      <td>&lt;sos&gt; yukos owner menatep group says it will a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>high fuel prices hit ba s profits british airw...</td>\n",
       "      <td>&lt;sos&gt; rod eddington ba s chief executive said ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>pernod takeover talk lifts domecq shares in uk...</td>\n",
       "      <td>&lt;sos&gt; pernod has reduced the debt it took on t...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                news  \\\n",
       "0  ad sales boost time warner profit quarterly pr...   \n",
       "1  dollar gains on greenspan speech the dollar ha...   \n",
       "2  yukos unit buyer faces loan claim the owners o...   \n",
       "3  high fuel prices hit ba s profits british airw...   \n",
       "4  pernod takeover talk lifts domecq shares in uk...   \n",
       "\n",
       "                                             summary  \n",
       "0  <sos> timewarner said fourth quarter sales ros...  \n",
       "1  <sos> the dollar has hit its highest level aga...  \n",
       "2  <sos> yukos owner menatep group says it will a...  \n",
       "3  <sos> rod eddington ba s chief executive said ...  \n",
       "4  <sos> pernod has reduced the debt it took on t...  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"summary\"]='<sos> '+df[\"summary\"]+' <eos>'\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9a0f096c",
   "metadata": {},
   "outputs": [],
   "source": [
    "PAD = \"<pad>\"\n",
    "SOS = \"<sos>\"\n",
    "EOS = \"<eos>\"\n",
    "UNK = \"<unk>\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be3880fa",
   "metadata": {},
   "source": [
    "Ref: GPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4f993e01",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "class Vocab:\n",
    "    def __init__(self, texts, max_size=30000, min_freq=2):\n",
    "        counter = Counter()\n",
    "        for text in texts:\n",
    "            counter.update(text.split())\n",
    "\n",
    "        self.itos = [PAD, SOS, EOS, UNK]\n",
    "        for word, freq in counter.most_common():\n",
    "            if freq >= min_freq and len(self.itos) < max_size:\n",
    "                self.itos.append(word)\n",
    "\n",
    "        self.stoi = {word: idx for idx, word in enumerate(self.itos)}\n",
    "\n",
    "    def encode(self, text):\n",
    "        return [self.stoi.get(w, self.stoi[UNK]) for w in text.split()]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.itos)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e38733a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Article Vocab Size: 18730\n",
      "Summary Vocab Size: 12388\n"
     ]
    }
   ],
   "source": [
    "article_vocab = Vocab(df[\"news\"], max_size=30000)\n",
    "summary_vocab = Vocab(df[\"summary\"], max_size=15000)\n",
    "print(f\"Article Vocab Size: {len(article_vocab)}\")\n",
    "print(f\"Summary Vocab Size: {len(summary_vocab)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef1008f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset,DataLoader\n",
    "import torch\n",
    "class SummaryDataset(Dataset):\n",
    "    def __init__(self,df,article_vocab,summary_vocab,max_article_len=512,max_summary_len=100):\n",
    "        super().__init__()\n",
    "        self.df=df\n",
    "        self.article_vocab=article_vocab\n",
    "        self.summary_vocab=summary_vocab\n",
    "        self.max_article_len=max_article_len\n",
    "        self.max_summary_len=max_summary_len\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def pad(self, sequence, max_length, pad_idx):\n",
    "        return sequence[:max_length] + [pad_idx] * (max_length - len(sequence))\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        article=self.df.iloc[idx][\"news\"] # get the article text of the given index\n",
    "        summary=self.df.iloc[idx][\"summary\"] # get the summary text of the given index\n",
    "        print(f\"Summary: {summary}\")\n",
    "        enc=self.article_vocab.encode(article) # encode the article text\n",
    "        dec=self.summary_vocab.encode(summary) # encode the summary text\n",
    "        \n",
    "        print(f\"Encoded Summary: {dec}\")\n",
    "        print(f\"Length before padding: {len(dec)}\")\n",
    "        enc=self.pad(enc,self.max_article_len,self.article_vocab.stoi[PAD]) # pad the encoded article\n",
    "        dec=self.pad(dec,self.max_summary_len,self.summary_vocab.stoi[PAD]) # pad the encoded summary\n",
    "        print(f\"Padded Summary: {dec}\")\n",
    "        print(f\"Length after padding: {len(dec)}\")\n",
    "        return torch.tensor(enc), torch.tensor(dec) # return the padded tensors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10db29c3",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üîç Understanding the Padding Logic\n",
    "\n",
    "The `pad()` function does **TWO things**:\n",
    "\n",
    "```python\n",
    "def pad(self, sequence, max_length, pad_idx):\n",
    "    return sequence[:max_length] + [pad_idx] * (max_length - len(sequence))\n",
    "```\n",
    "\n",
    "### 1Ô∏è‚É£ **If sequence is LONGER than max_length: TRUNCATE**\n",
    "```python\n",
    "sequence = [1, 2, 3, 4, 5, 6, 7, 8]  # length = 8\n",
    "max_length = 5\n",
    "pad_idx = 0\n",
    "\n",
    "# Step 1: sequence[:max_length] = [1, 2, 3, 4, 5]  (first 5 only)\n",
    "# Step 2: [0] * (5 - 5) = []  (no padding needed, already 5)\n",
    "\n",
    "Result: [1, 2, 3, 4, 5]  ‚úÇÔ∏è CUT OFF!\n",
    "```\n",
    "\n",
    "### 2Ô∏è‚É£ **If sequence is SHORTER than max_length: PAD**\n",
    "```python\n",
    "sequence = [1, 2, 3]  # length = 3\n",
    "max_length = 5\n",
    "pad_idx = 0\n",
    "\n",
    "# Step 1: sequence[:max_length] = [1, 2, 3]  (all of it)\n",
    "# Step 2: [0] * (5 - 3) = [0, 0]  (add 2 padding tokens)\n",
    "\n",
    "Result: [1, 2, 3, 0, 0]  ‚úèÔ∏è PADDED!\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## üìä Your Examples\n",
    "\n",
    "### Example 1: LONG SEQUENCE (gets truncated)\n",
    "```\n",
    "Encoded Summary length: 254\n",
    "max_length: 50\n",
    "\n",
    "# Sequence is much longer than 50!\n",
    "sequence[:50] = [22, 4, 5045, ..., 132, 54, 5569, 55]  (first 50)\n",
    "[0] * (50 - 50) = []  (nothing to add)\n",
    "\n",
    "Result: [22, 4, 5045, ..., 54, 5569, 55]  ‚úÇÔ∏è TRUNCATED to 50\n",
    "# You only see the FIRST 50 tokens, rest is discarded!\n",
    "```\n",
    "\n",
    "### Example 2: EVEN LONGER SEQUENCE (still gets truncated)\n",
    "```\n",
    "Encoded Summary length: 84\n",
    "max_length: 50\n",
    "\n",
    "# Sequence is longer than 50\n",
    "sequence[:50] = [22, 45, 59, ..., 570]  (first 50)\n",
    "[0] * (50 - 50) = []  (nothing to add)\n",
    "\n",
    "Result: [22, 45, 59, ..., 570]  ‚úÇÔ∏è TRUNCATED to 50\n",
    "# Again, only first 50 tokens kept!\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## üîë Key Point\n",
    "\n",
    "**The padding in your dataset is mostly TRUNCATION, not padding!**\n",
    "\n",
    "Why? Because actual BBC news summaries are usually **longer than 50 tokens**.\n",
    "\n",
    "To see actual padding in action, you'd need a shorter summary:\n",
    "\n",
    "```python\n",
    "sequence = [22, 45, 59, 7864, ..., 941, 82]  # length = 30\n",
    "max_length = 50\n",
    "pad_idx = 0\n",
    "\n",
    "Result: [22, 45, 59, 7864, ..., 941, 82, 0, 0, 0, ..., 0]\n",
    "         ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
    "              30 real tokens                20 padding tokens (0s)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## üí° Why Truncate?\n",
    "\n",
    "The model needs **consistent input shapes**:\n",
    "- All encoder inputs: `(batch_size, 512)` tokens\n",
    "- All decoder inputs: `(batch_size, 50)` tokens\n",
    "\n",
    "If summaries are longer than 50, we **truncate** to the first 50 tokens (keep the beginning).\n",
    "\n",
    "If summaries are shorter than 50, we **pad** with `<pad>` tokens to reach 50."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "57433986",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset=SummaryDataset(df,article_vocab,summary_vocab)\n",
    "loader=DataLoader(dataset,batch_size=2,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5f5ddec6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary: <sos> the explosion in consumer technology is to continue into delegates at the world s largest gadget show in las vegas have been told the consumer electronics show ces featured the pick of s products the portable technologies on show also reflected one of the buzzwords of ces which was the time and place shifting of multimedia content being able to watch and listen to video and music anywhere at any time another disappointment was the lack of exposure sony s new portable games device the psp had at the show a sony representative told the bbc news website this was because sony did not consider it to be part of their consumer technology offering he unveiled new ways of letting people take tv shows recorded on personal video recorders and watch them back on portable devices everything is going digital kirsten pfeifer from the consumer electronics association told the bbc news website hybrid devices which combine a number of multimedia functions were also in evidence on the show floor as well as the show floor showcasing everything from tiny wearable mp players to giant high definition tvs several keynote speeches were made by industry leaders such as microsoft chief bill gates all the products on show really showed the breadth and depth of the industry that figure was surpassed with the rise in popularity of portable digital music players personal video recorders and digital cameras more than of the consumer electronics market is made up of female buyers according to cea research <eos>\n",
      "Encoded Summary: [22, 4, 5045, 8, 465, 144, 14, 5, 582, 80, 3185, 25, 4, 76, 12, 693, 775, 132, 8, 2683, 2819, 28, 41, 96, 4, 465, 1232, 132, 2578, 4406, 4, 2385, 6, 12, 867, 4, 853, 895, 16, 132, 54, 5569, 55, 6, 4, 9183, 6, 2578, 40, 15, 4, 68, 9, 266, 5780, 6, 1336, 427, 93, 368, 5, 983, 9, 2257, 5, 200, 9, 81, 3293, 25, 113, 68, 263, 4125, 15, 4, 1314, 6, 3285, 613, 12, 49, 853, 121, 984, 4, 2453, 37, 25, 4, 132, 7, 613, 3544, 96, 4, 115, 209, 518, 46, 15, 102, 613, 133, 30, 1422, 17, 5, 20, 156, 6, 44, 465, 144, 1186, 19, 1429, 49, 846, 6, 2652, 47, 116, 146, 573, 1439, 16, 425, 200, 3012, 9, 983, 105, 100, 16, 853, 697, 1183, 14, 186, 185, 12211, 12212, 33, 4, 465, 1232, 680, 96, 4, 115, 209, 518, 2505, 697, 40, 3878, 7, 106, 6, 1336, 3529, 52, 54, 8, 533, 16, 4, 132, 3793, 24, 129, 24, 4, 132, 3793, 5480, 1183, 33, 5062, 6497, 734, 173, 5, 572, 167, 1024, 3500, 634, 4232, 4575, 52, 108, 26, 212, 1201, 118, 24, 343, 221, 356, 2175, 70, 4, 867, 16, 132, 350, 547, 4, 12213, 9, 4303, 6, 4, 212, 13, 1129, 15, 5441, 21, 4, 313, 8, 2395, 6, 853, 185, 81, 173, 425, 200, 3012, 9, 185, 1559, 45, 59, 6, 4, 465, 1232, 126, 14, 108, 50, 6, 1326, 2476, 205, 5, 3677, 340, 23]\n",
      "Length before padding: 254\n",
      "Padded Summary: [22, 4, 5045, 8, 465, 144, 14, 5, 582, 80, 3185, 25, 4, 76, 12, 693, 775, 132, 8, 2683, 2819, 28, 41, 96, 4, 465, 1232, 132, 2578, 4406, 4, 2385, 6, 12, 867, 4, 853, 895, 16, 132, 54, 5569, 55, 6, 4, 9183, 6, 2578, 40, 15]\n",
      "Length after padding: 50\n",
      "Summary: <sos> more than britannia building society members are to receive a profit share worth on average each last year britannia members shared m but the average payment was only britannia has also stopped making payments to members if they are worth less than to qualify for the profit share members must have either a mortgage or an investment account other than a deposit account to qualify for this year s payment customers must have been members for at least two years on december <eos>\n",
      "Encoded Summary: [22, 45, 59, 7864, 1394, 1277, 570, 32, 5, 1156, 7, 926, 433, 947, 16, 838, 510, 66, 42, 7864, 570, 2012, 57, 29, 4, 838, 3734, 15, 94, 7864, 18, 54, 2323, 307, 2315, 5, 570, 63, 39, 32, 947, 344, 59, 5, 3479, 11, 4, 926, 433, 570, 578, 28, 818, 7, 1707, 65, 38, 513, 941, 82, 59, 7, 4823, 941, 5, 3479, 11, 46, 42, 12, 3734, 668, 578, 28, 41, 570, 11, 25, 514, 69, 86, 16, 314, 23]\n",
      "Length before padding: 84\n",
      "Padded Summary: [22, 45, 59, 7864, 1394, 1277, 570, 32, 5, 1156, 7, 926, 433, 947, 16, 838, 510, 66, 42, 7864, 570, 2012, 57, 29, 4, 838, 3734, 15, 94, 7864, 18, 54, 2323, 307, 2315, 5, 570, 63, 39, 32, 947, 344, 59, 5, 3479, 11, 4, 926, 433, 570]\n",
      "Length after padding: 50\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[tensor([[1014,  121,    5,  ...,  445,   36,   17],\n",
       "         [8791,  536,   57,  ...,    0,    0,    0]]),\n",
       " tensor([[  22,    4, 5045,    8,  465,  144,   14,    5,  582,   80, 3185,   25,\n",
       "             4,   76,   12,  693,  775,  132,    8, 2683, 2819,   28,   41,   96,\n",
       "             4,  465, 1232,  132, 2578, 4406,    4, 2385,    6,   12,  867,    4,\n",
       "           853,  895,   16,  132,   54, 5569,   55,    6,    4, 9183,    6, 2578,\n",
       "            40,   15],\n",
       "         [  22,   45,   59, 7864, 1394, 1277,  570,   32,    5, 1156,    7,  926,\n",
       "           433,  947,   16,  838,  510,   66,   42, 7864,  570, 2012,   57,   29,\n",
       "             4,  838, 3734,   15,   94, 7864,   18,   54, 2323,  307, 2315,    5,\n",
       "           570,   63,   39,   32,  947,  344,   59,    5, 3479,   11,    4,  926,\n",
       "           433,  570]])]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(loader))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "566c8939",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üé¨ Complete Data Flow Visualization\n",
    "\n",
    "Let's trace how a **real batch** flows through the entire system!\n",
    "\n",
    "### üìä Input Batch Example:\n",
    "```python\n",
    "enc_batch shape: (4, 512)   # 4 articles, each 512 tokens\n",
    "dec_batch shape: (4, 50)    # 4 summaries, each 50 tokens\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### üîÑ **TRAINING FLOW** (forward function)\n",
    "\n",
    "```\n",
    "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
    "‚îÇ STEP 1: ENCODER - \"Understanding the Article\"              ‚îÇ\n",
    "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
    "\n",
    "enc_batch: (4, 512)  ‚Üí [4052, 187, 700, 71, ...]\n",
    "    ‚Üì\n",
    "Embedding: (4, 512, 256)  ‚Üí Each token becomes a 256-d vector\n",
    "    ‚Üì\n",
    "LSTM processes all 512 tokens:\n",
    "    Token 0: [4052] ‚Üí hidden state update\n",
    "    Token 1: [187]  ‚Üí hidden state update\n",
    "    ...\n",
    "    Token 511: [...]‚Üí Final hidden state\n",
    "    ‚Üì\n",
    "encoder_hidden (h): (1, 4, 512)  ‚Üê Compressed understanding!\n",
    "encoder_cell (c):   (1, 4, 512)  ‚Üê Memory!\n",
    "\n",
    "\n",
    "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
    "‚îÇ STEP 2: DECODER - \"Generating Summary Word by Word\"        ‚îÇ\n",
    "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
    "\n",
    "Initial Input: dec_in_seq[:, 0] = <SOS> token for all 4 samples\n",
    "              Shape: (4,)  ‚Üí [22, 22, 22, 22]\n",
    "\n",
    "‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó\n",
    "‚ïë TIME STEP 0: Generate 1st word                            ‚ïë\n",
    "‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù\n",
    "\n",
    "current_input: (4,) = [22, 22, 22, 22]  (<SOS>)\n",
    "    ‚Üì\n",
    "unsqueeze(1): (4, 1)\n",
    "    ‚Üì\n",
    "Embedding: (4, 1, 256)\n",
    "    ‚Üì\n",
    "LSTM(embedding, h, c):\n",
    "    - Uses context from encoder (h, c)\n",
    "    - Output: (4, 1, 512)\n",
    "    ‚Üì\n",
    "squeeze(1): (4, 512)\n",
    "    ‚Üì\n",
    "FC Layer: (4, vocab_size)  ‚Üí [0.01, 0.05, 0.8, 0.02, ...]\n",
    "                             ‚Üì\n",
    "Store in all_decoder_outputs[:, 0, :]\n",
    "\n",
    "Teacher Forcing Decision:\n",
    "    random() < 0.5?\n",
    "    ‚îú‚îÄ YES: next_input = dec_in_seq[:, 1] (real target word)\n",
    "    ‚îî‚îÄ NO:  next_input = argmax(predictions) (model's guess)\n",
    "\n",
    "‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó\n",
    "‚ïë TIME STEP 1: Generate 2nd word                            ‚ïë\n",
    "‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù\n",
    "\n",
    "current_input: (4,) = [506, 506, 336, 506] (from previous step)\n",
    "    ‚Üì\n",
    "unsqueeze(1): (4, 1)\n",
    "    ‚Üì\n",
    "Embedding: (4, 1, 256)\n",
    "    ‚Üì\n",
    "LSTM(embedding, h_updated, c_updated):  ‚Üê h and c evolve!\n",
    "    - Output: (4, 1, 512)\n",
    "    ‚Üì\n",
    "FC Layer: (4, vocab_size)\n",
    "    ‚Üì\n",
    "Store in all_decoder_outputs[:, 1, :]\n",
    "\n",
    "... Repeat for all 50 time steps ...\n",
    "\n",
    "‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó\n",
    "‚ïë TIME STEP 49: Generate 50th word                          ‚ïë\n",
    "‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù\n",
    "\n",
    "Final all_decoder_outputs: (4, 50, vocab_size)\n",
    "\n",
    "\n",
    "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
    "‚îÇ STEP 3: LOSS CALCULATION                                   ‚îÇ\n",
    "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
    "\n",
    "outputs: (4, 50, 5000) ‚Üí Reshape ‚Üí (200, 5000)\n",
    "targets: (4, 50)       ‚Üí Reshape ‚Üí (200,)\n",
    "    ‚Üì\n",
    "CrossEntropyLoss:\n",
    "    Compare 200 predictions with 200 target words\n",
    "    Calculate average loss\n",
    "    ‚Üì\n",
    "Backward: Update all weights to minimize loss!\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### üéØ **INFERENCE FLOW** (after training)\n",
    "\n",
    "```\n",
    "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
    "‚îÇ User provides new article (not in training data)           ‚îÇ\n",
    "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
    "\n",
    "Article: \"The economy grew by 5% last quarter...\"\n",
    "    ‚Üì\n",
    "Encode + Tokenize: [1234, 5678, ...]\n",
    "    ‚Üì\n",
    "Encoder: h, c (context)\n",
    "    ‚Üì\n",
    "Decoder Loop:\n",
    "    Start: <SOS>\n",
    "    Time 0: <SOS> ‚Üí \"economy\"\n",
    "    Time 1: \"economy\" ‚Üí \"grows\"\n",
    "    Time 2: \"grows\" ‚Üí \"5%\" \n",
    "    Time 3: \"5%\" ‚Üí <EOS> (STOP!)\n",
    "    ‚Üì\n",
    "Summary: \"economy grows 5%\"\n",
    "```\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "444199f4",
   "metadata": {},
   "source": [
    "\n",
    "## Architecture Components\n",
    "\n",
    "### 1. **Embedding Layer** - Converting Words to Numbers\n",
    "\n",
    "**Problem:** Neural networks don't understand words like \"cat\" or \"dog\"\n",
    "\n",
    "**Solution:** Convert each word to a dense vector of numbers\n",
    "\n",
    "```\n",
    "Word: \"scientist\" (ID=4052)\n",
    "    ‚Üì\n",
    "Embedding Layer\n",
    "    ‚Üì\n",
    "Vector: [0.23, -0.45, 0.67, ..., 0.12]  # 256 dimensions\n",
    "```\n",
    "\n",
    "**Why 256 dimensions?**\n",
    "- Captures semantic meaning (similar words have similar vectors)\n",
    "- Learned during training\n",
    "- Trade-off: Higher = more capacity, but slower training\n",
    "\n",
    "**Mathematical Operation:**\n",
    "```python\n",
    "embedding = nn.Embedding(vocab_size=10000, embed_dim=256)\n",
    "x = torch.tensor([4052])  # Word ID\n",
    "embedded = embedding(x)   # Shape: (1, 256)\n",
    "```\n",
    "\n",
    "This is essentially a **lookup table**:\n",
    "```\n",
    "embedding.weight[4052] ‚Üí [0.23, -0.45, 0.67, ...]\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### 2. **LSTM (Long Short-Term Memory)** - The Memory Unit\n",
    "\n",
    "**Why LSTM and not simple RNN?**\n",
    "\n",
    "**Problem with Simple RNNs:**\n",
    "```\n",
    "Sentence: \"The cat, which was very fluffy and cute, sat on the mat\"\n",
    "\n",
    "When processing \"sat\", simple RNN forgets \"cat\" (vanishing gradient)\n",
    "```\n",
    "\n",
    "**In Our Code:**\n",
    "```python\n",
    "self.lstm = nn.LSTM(embed_dim=256, hidden_dim=512, batch_first=True)\n",
    "\n",
    "# embed_dim=256: Input size (word embedding)\n",
    "# hidden_dim=512: Size of hidden state and cell state\n",
    "# batch_first=True: Input shape is (batch, seq_len, features)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### 3. **Encoder Architecture**\n",
    "\n",
    "**Purpose:** Compress the entire input sequence into a fixed-size representation\n",
    "\n",
    "```python\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim, hidden_dim):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_dim, padding_idx=0)\n",
    "        self.lstm = nn.LSTM(embed_dim, hidden_dim, batch_first=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        emb = self.embedding(x)              # (batch, seq, embed)\n",
    "        outputs, (h, c) = self.lstm(emb)     # Process sequence\n",
    "        return h, c                          # Return final states only\n",
    "```\n",
    "\n",
    "**Key Point:** We **discard `outputs`** and only keep **`h`** and **`c`**!\n",
    "\n",
    "**Why?**\n",
    "- `outputs`: Hidden state at **every** time step (batch, seq_len, hidden_dim)\n",
    "- `h`: Hidden state at the **last** time step (1, batch, hidden_dim)\n",
    "- `c`: Cell state at the **last** time step (1, batch, hidden_dim)\n",
    "\n",
    "The final `h` and `c` are the **compressed representation** of the entire article!\n",
    "\n",
    "**Information Flow:**\n",
    "```\n",
    "Token 0: \"The\"        ‚Üí h‚ÇÄ, c‚ÇÄ\n",
    "Token 1: \"scientist\"  ‚Üí h‚ÇÅ, c‚ÇÅ (remembers \"The\" + \"scientist\")\n",
    "Token 2: \"discovered\" ‚Üí h‚ÇÇ, c‚ÇÇ (remembers all previous)\n",
    "...\n",
    "Token 511: \".\"        ‚Üí h‚ÇÖ‚ÇÅ‚ÇÅ, c‚ÇÖ‚ÇÅ‚ÇÅ (remembers ENTIRE article!)\n",
    "\n",
    "We use h‚ÇÖ‚ÇÅ‚ÇÅ and c‚ÇÖ‚ÇÅ‚ÇÅ as context for decoder!\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### 4. **Decoder Architecture**\n",
    "\n",
    "**Purpose:** Generate output sequence one word at a time, conditioned on encoder's context\n",
    "\n",
    "```python\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim, hidden_dim):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_dim, padding_idx=0)\n",
    "        self.lstm = nn.LSTM(embed_dim, hidden_dim, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_dim, vocab_size)\n",
    "\n",
    "    def forward(self, x, h, c):\n",
    "        x = x.unsqueeze(1)                    # (batch,) ‚Üí (batch, 1)\n",
    "        emb = self.embedding(x)               # (batch, 1, embed)\n",
    "        output, (h, c) = self.lstm(emb, (h, c))  # Use encoder's h, c!\n",
    "        pred = self.fc(output.squeeze(1))     # (batch, vocab_size)\n",
    "        return pred, h, c\n",
    "```\n",
    "\n",
    "**Key Differences from Encoder:**\n",
    "\n",
    "1. **Input Shape:** \n",
    "   - Encoder: Processes entire sequence (batch, 512)\n",
    "   - Decoder: Processes ONE token at a time (batch, 1)\n",
    "\n",
    "2. **Initial Hidden State:**\n",
    "   - Encoder: Starts with zeros\n",
    "   - Decoder: Starts with encoder's final h and c\n",
    "\n",
    "3. **Output:**\n",
    "   - Encoder: Returns only h, c\n",
    "   - Decoder: Returns predictions + updated h, c\n",
    "\n",
    "**The FC Layer:**\n",
    "```python\n",
    "self.fc = nn.Linear(hidden_dim=512, vocab_size=5000)\n",
    "```\n",
    "\n",
    "Converts LSTM's hidden state ‚Üí probability distribution over vocabulary\n",
    "\n",
    "```\n",
    "LSTM output: [0.23, -0.45, 0.67, ...]  (512 values)\n",
    "    ‚Üì\n",
    "FC Layer (linear transformation + softmax)\n",
    "    ‚Üì\n",
    "Probabilities: [0.001, 0.002, 0.8, 0.001, ...]  (5000 values)\n",
    "                  ‚Üë\n",
    "             \"scientist\" (highest probability!)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### 5. **Seq2Seq Model - Connecting Everything**\n",
    "\n",
    "This is the **orchestrator** that combines encoder and decoder:\n",
    "\n",
    "## Training Concepts\n",
    "\n",
    "### **Teacher Forcing** - The Training Trick\n",
    "\n",
    "**Problem:** During training, if model makes one mistake, all subsequent predictions are wrong!\n",
    "\n",
    "```\n",
    "Target:  \"scientist\" \"discover\" \"planet\"\n",
    "Predict: \"scientist\" \"found\"    \"star\"    ‚Üê One mistake cascades!\n",
    "                        ‚Üë               \n",
    "                  Wrong prediction makes next prediction harder\n",
    "```\n",
    "\n",
    "**Solution: Teacher Forcing**\n",
    "\n",
    "With probability 0.5, use the **real target word** instead of prediction:\n",
    "\n",
    "```\n",
    "Time 0: Model predicts \"scientist\" ‚úì\n",
    "        Next input = \"scientist\" (ground truth)\n",
    "\n",
    "Time 1: Model predicts \"found\" ‚úó (wrong)\n",
    "        Next input = \"discover\" (ground truth - teacher forcing!)\n",
    "\n",
    "Time 2: Model predicts \"planet\" ‚úì (correct because input was right)\n",
    "```\n",
    "\n",
    "**Trade-off:**\n",
    "- Too much teacher forcing (1.0): Model never learns to correct its mistakes\n",
    "- Too little teacher forcing (0.0): Training is unstable\n",
    "- Sweet spot: 0.5 - 0.6\n",
    "\n",
    "---\n",
    "\n",
    "### **Loss Calculation**\n",
    "\n",
    "```python\n",
    "outputs = model(enc_batch, dec_input)  # (4, 50, 5000)\n",
    "targets = dec_batch[:, 1:]             # (4, 50)\n",
    "\n",
    "# Reshape for CrossEntropyLoss\n",
    "outputs = outputs.reshape(-1, 5000)    # (200, 5000)\n",
    "targets = targets.reshape(-1)          # (200,)\n",
    "\n",
    "loss = CrossEntropyLoss(outputs, targets)\n",
    "```\n",
    "\n",
    "**Why reshape?**\n",
    "\n",
    "CrossEntropyLoss expects:\n",
    "- **Predictions:** (N, C) where N=number of predictions, C=number of classes\n",
    "- **Targets:** (N,) with class indices\n",
    "\n",
    "We have 4 samples √ó 50 words = 200 predictions total!\n",
    "\n",
    "**Mathematical Formula:**\n",
    "```\n",
    "Loss = -‚àë log(p(target_word))\n",
    "\n",
    "For each position, penalize if model didn't give high probability to target word\n",
    "```\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "ae560fe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim, hidden_dim):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_dim, padding_idx=0)\n",
    "        self.lstm = nn.LSTM(embed_dim, hidden_dim, batch_first=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        emb = self.embedding(x)\n",
    "        outputs, (h, c) = self.lstm(emb)\n",
    "        return h, c"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "084da456",
   "metadata": {},
   "source": [
    "### üìñ Encoder Explained\n",
    "\n",
    "The **Encoder** reads the entire article and creates a \"memory\" of it.\n",
    "\n",
    "**Components:**\n",
    "- **Embedding Layer**: Converts word IDs ‚Üí dense vectors (numbers the model can work with)\n",
    "- **LSTM Layer**: Processes the sequence and creates hidden state (h) and cell state (c)\n",
    "\n",
    "**Data Flow Example:**\n",
    "```\n",
    "Input: [4052, 187, 700, ...]  # Word IDs (batch_size=4, seq_len=512)\n",
    "    ‚Üì\n",
    "Embedding: [[0.2, 0.5, ...], [0.1, 0.3, ...], ...]  # Shape: (4, 512, 256)\n",
    "    ‚Üì\n",
    "LSTM: Processes sequence step-by-step\n",
    "    ‚Üì\n",
    "Output: \n",
    "  - h (hidden state): (1, 4, 512) - The \"summary\" of the article\n",
    "  - c (cell state): (1, 4, 512) - The \"memory\" LSTM keeps\n",
    "```\n",
    "\n",
    "**Why h and c?**\n",
    "- **h (hidden)**: What the model \"understood\" from the article\n",
    "- **c (cell)**: What the model \"remembers\" for later use\n",
    "\n",
    "These become the starting point for the decoder!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a44805ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim, hidden_dim):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_dim, padding_idx=0)\n",
    "        self.lstm = nn.LSTM(embed_dim, hidden_dim, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_dim, vocab_size)\n",
    "\n",
    "    def forward(self, x, h, c):\n",
    "        x = x.unsqueeze(1) # Add sequence dimension (batch_size, 1, input_size) as lstm expects 3D input\n",
    "        emb = self.embedding(x)\n",
    "        output, (h, c) = self.lstm(emb, (h, c))\n",
    "        pred = self.fc(output.squeeze(1)) # remove sequence dimension added earlier\n",
    "        return pred, h, c"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e63a9bb5",
   "metadata": {},
   "source": [
    "### Decoder Explained\n",
    "\n",
    "The **Decoder** generates the summary one word at a time using the encoder's context.\n",
    "\n",
    "**Key Difference from Encoder:**\n",
    "- Encoder processes the **entire sequence at once**\n",
    "- Decoder processes **one word at a time** (autoregressive)\n",
    "\n",
    "**Components:**\n",
    "- **Embedding Layer**: Converts target word ID ‚Üí vector\n",
    "- **LSTM Layer**: Takes embedding + previous hidden/cell states ‚Üí generates next state\n",
    "- **Fully Connected (fc)**: Converts LSTM output ‚Üí vocabulary probabilities\n",
    "\n",
    "**Data Flow Example:**\n",
    "```\n",
    "Step 1:\n",
    "  Input: <SOS> token (ID=22)  # Shape: (4,) - batch of 4\n",
    "    ‚Üì\n",
    "  unsqueeze(1): (4, 1)  # Add sequence dimension (because we process 1 word at a time)\n",
    "    ‚Üì\n",
    "  Embedding: (4, 1, 256)\n",
    "    ‚Üì\n",
    "  LSTM (with h, c from encoder): (4, 1, 512)\n",
    "    ‚Üì\n",
    "  squeeze(1): (4, 512)\n",
    "    ‚Üì\n",
    "  fc layer: (4, vocab_size)  # Probability for each word in vocabulary\n",
    "    ‚Üì\n",
    "  Output: [0.01, 0.05, 0.8, ...]  # Model predicts next word\n",
    "\n",
    "Step 2:\n",
    "  Input: Predicted word from Step 1 (or ground truth if teacher forcing)\n",
    "  [Same process repeats...]\n",
    "```\n",
    "\n",
    "**Why unsqueeze(1)?**\n",
    "LSTM expects shape: `(batch_size, sequence_length, features)`\n",
    "But we feed one word at a time, so we add a fake sequence dimension of 1."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "882c0bf7",
   "metadata": {},
   "source": [
    "`x = x.unsqueeze(1)`\n",
    "\n",
    "Why?\n",
    "\n",
    "PyTorch LSTM expects:\n",
    "- (batch, seq_len, features)\n",
    "\n",
    "But x is:\n",
    "- (batch,)\n",
    "\n",
    "So we add a fake time dimension:\n",
    "- (batch, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95beb0e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SeqtoSeqModel(nn.Module):\n",
    "    def __init__(self, encoder_model ,decoder_model , computation_device):\n",
    "        super(SeqtoSeqModel, self).__init__()\n",
    "        \n",
    "        self.encoder_model  = encoder_model\n",
    "        self.decoder_model = decoder_model\n",
    "        self.device = computation_device\n",
    "        \n",
    "    def forward(self, enc_in_seq, dec_in_seq, teacher_forcing_ratio=0.5):\n",
    "        # First we get the dimensions and initialize the tensor to hold all decoder outputs\n",
    "        batch_size, decoder_sequence_length = dec_in_seq.shape\n",
    "        decoder_vocabulary_size = self.decoder_model.fc.out_features\n",
    "        \n",
    "        # INITIALIZE A TENSOR TO HOLD ALL DECODER OUTPUTS (Size : batch_size x decoder_sequence_length x decoder_vocabulary_size)\n",
    "        all_decoder_outputs = torch.zeros(batch_size, decoder_sequence_length, decoder_vocabulary_size, device=self.device)\n",
    "        \n",
    "        # ENCODER BLOCK ( GETTING CELL AND HIDDEN STATES FROM ENCODER)\n",
    "        enc_hidden, enc_cell = self.encoder_model(enc_in_seq)\n",
    "        current_decoder_input_token = dec_in_seq[:, 0]  # list[:, 0] means taking the first token/<sos> token of each sequence from the batch\n",
    "        \n",
    "        # DECODER BLOCK (ITERATING OVER EACH TIME STEP IN THE DECODER SEQUENCE)\n",
    "        for time_stamp in range(decoder_sequence_length):\n",
    "            predicted_token, enc_hidden, enc_cell = self.decoder_model(current_decoder_input_token, enc_hidden, enc_cell)\n",
    "            \n",
    "            all_decoder_outputs[:, time_stamp, :] = predicted_token # from each batch get the time_stamp predicted token only\n",
    "            use_teacher_forcing = (torch.rand(1).item() < teacher_forcing_ratio) and (time_stamp + 1 < decoder_sequence_length) \n",
    "            \n",
    "            if use_teacher_forcing:\n",
    "                current_decoder_input_token = dec_in_seq[:, time_stamp + 1]\n",
    "            else:\n",
    "                current_decoder_input_token = predicted_token.argmax(dim=1)\n",
    "                \n",
    "        return all_decoder_outputs\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8b37cf9",
   "metadata": {},
   "source": [
    "\n",
    "**What happens in each loop iteration:**\n",
    "\n",
    "**Time=0:** Generate 1st word\n",
    "```\n",
    "current_input: <SOS>\n",
    "    ‚Üì\n",
    "Decoder(input=<SOS>, h, c)\n",
    "    ‚Üì\n",
    "predicted_logits: [0.01, 0.8, 0.05, ...]  # Probabilities for all words\n",
    "    ‚Üì\n",
    "Store in all_decoder_outputs[:, 0, :]\n",
    "    ‚Üì\n",
    "Teacher Forcing Decision:\n",
    "  - If random() < 0.5: Use REAL next word from ground truth (dec_in_seq[:, 1])\n",
    "  - Else: Use PREDICTED word (argmax of logits)\n",
    "```\n",
    "\n",
    "**Time=1:** Generate 2nd word\n",
    "```\n",
    "current_input: Word from time=0 (either real or predicted)\n",
    "    ‚Üì\n",
    "Decoder(input=word1, h, c)  # h and c are updated from previous step!\n",
    "    ‚Üì\n",
    "predicted_logits for 2nd word\n",
    "    ‚Üì\n",
    "Store in all_decoder_outputs[:, 1, :]\n",
    "```\n",
    "\n",
    "...continues for 50 time steps...\n",
    "\n",
    "#### **Step 5: Return All Predictions**\n",
    "```python\n",
    "return all_decoder_outputs  # Shape: (4, 50, 5000)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "99f4a775",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "embed_dim = 256\n",
    "hidden_dim = 512\n",
    "\n",
    "encoder = Encoder(len(article_vocab), embed_dim, hidden_dim)\n",
    "decoder = Decoder(len(summary_vocab), embed_dim, hidden_dim)\n",
    "\n",
    "sequence_to_sequence_model = SeqtoSeqModel(encoder, decoder, device).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "7898f53e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pad_idx = summary_vocab.stoi[PAD]\n",
    "loss_function = nn.CrossEntropyLoss(ignore_index=pad_idx)\n",
    "optimizer = torch.optim.Adam(\n",
    "    sequence_to_sequence_model.parameters(),\n",
    "    lr=0.001\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "027d7166",
   "metadata": {},
   "source": [
    "### Model Instantiation\n",
    "\n",
    "Creating the actual model with specific dimensions:\n",
    "\n",
    "```\n",
    "article_vocab size: ~10,000 words\n",
    "summary_vocab size: ~5,000 words\n",
    "embed_dim: 256 (each word ‚Üí 256-dimensional vector)\n",
    "hidden_dim: 512 (LSTM internal state size)\n",
    "```\n",
    "\n",
    "The model is moved to GPU (if available) for faster training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ed909dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.utils import clip_grad_norm_\n",
    "from tqdm import tqdm\n",
    "\n",
    "num_epochs = 20\n",
    "teacher_forcing_ratio = 0.6\n",
    "\n",
    "sequence_to_sequence_model.train()\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    epoch_loss = 0.0\n",
    "    for enc_batch, dec_batch in tqdm(loader, desc=f\"Epoch {epoch+1}/{num_epochs}\"):\n",
    "        enc_batch = enc_batch.to(device)\n",
    "        dec_batch = dec_batch.to(device)\n",
    "\n",
    "        dec_input = dec_batch[:, :-1] # all tokens except the last\n",
    "        targets = dec_batch[:, 1:] # all tokens except the first\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        outputs = sequence_to_sequence_model(enc_batch, dec_input, teacher_forcing_ratio=teacher_forcing_ratio)\n",
    "        \n",
    "        outputs = outputs.reshape(-1, outputs.size(-1)) # flatten the outputs for loss calculation\n",
    "        targets = targets.reshape(-1) # flatten the targets for loss calculation\n",
    "\n",
    "        loss = loss_function(outputs, targets)\n",
    "        loss.backward()\n",
    "        clip_grad_norm_(sequence_to_sequence_model.parameters(), 1.0)\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "    avg_loss = epoch_loss / len(loader)\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs} - Loss: {avg_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cd2627d",
   "metadata": {},
   "source": [
    "### üéì Training Loop Explained\n",
    "\n",
    "This is where the model learns! Let's break down what happens in each batch:\n",
    "\n",
    "#### **Data Preparation:**\n",
    "```python\n",
    "dec_input = dec_batch[:, :-1]   # All words except last: [<SOS>, word1, word2, ..., wordN-1]\n",
    "targets = dec_batch[:, 1:]      # All words except first: [word1, word2, ..., wordN, <EOS>]\n",
    "```\n",
    "\n",
    "**Why this split?**\n",
    "- Decoder gets: `<SOS> cat on` ‚Üí Should predict: `cat on mat`\n",
    "- We shift by 1 position to create input-target pairs\n",
    "\n",
    "#### **Forward Pass:**\n",
    "```python\n",
    "outputs = model(enc_batch, dec_input, teacher_forcing_ratio=0.6)\n",
    "# Shape: (batch=4, seq_len=49, vocab_size=5000)\n",
    "```\n",
    "\n",
    "#### **Reshape for Loss Calculation:**\n",
    "```python\n",
    "outputs = outputs.reshape(-1, outputs.size(-1))  # (4*49, 5000) = (196, 5000)\n",
    "targets = targets.reshape(-1)                     # (4*49,) = (196,)\n",
    "```\n",
    "**Why?** CrossEntropyLoss expects:\n",
    "- Predictions: (num_predictions, num_classes)\n",
    "- Targets: (num_predictions,)\n",
    "\n",
    "We treat each word prediction independently!\n",
    "\n",
    "#### **Backward Pass:**\n",
    "```python\n",
    "loss.backward()                                  # Calculate gradients\n",
    "clip_grad_norm_(model.parameters(), 1.0)        # Prevent exploding gradients\n",
    "optimizer.step()                                 # Update weights\n",
    "```\n",
    "\n",
    "#### **Visual Example of One Training Step:**\n",
    "\n",
    "```\n",
    "Batch Input:\n",
    "  Article: [4052, 187, 700, ...]  (batch=4, seq=512)\n",
    "  Summary: [22, 506, 336, 168, 603, ...]  (batch=4, seq=50)\n",
    "\n",
    "Split Summary:\n",
    "  dec_input: [22, 506, 336, 168]  (first 49 tokens)\n",
    "  targets:   [506, 336, 168, 603] (last 49 tokens)\n",
    "\n",
    "Model Forward:\n",
    "  Time 0: Input=22(<SOS>)  ‚Üí Predict: 506  vs Target: 506 ‚úì\n",
    "  Time 1: Input=506        ‚Üí Predict: 330  vs Target: 336 ‚úó (loss!)\n",
    "  Time 2: Input=336        ‚Üí Predict: 170  vs Target: 168 ‚úó (loss!)\n",
    "  ...\n",
    "\n",
    "Total Loss: Sum of all mismatches\n",
    "Backward: Adjust weights to reduce loss\n",
    "```\n",
    "\n",
    "**Over 20 epochs**, the model learns to generate better summaries!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f64b2f6",
   "metadata": {},
   "source": [
    "### üìâ Loss Function & Optimizer\n",
    "\n",
    "**CrossEntropyLoss:** Compares predicted word probabilities with actual words\n",
    "- `ignore_index=pad_idx`: Don't penalize the model for predicting padding\n",
    "\n",
    "**Adam Optimizer:** Adjusts model weights to minimize loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "254771cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_text(model, article, article_vocab, summary_vocab, device, max_summary_len=50):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        enc_input = torch.tensor(article_vocab.encode(article)).unsqueeze(0).to(device)\n",
    "        enc_hidden, enc_cell = model.encoder_model(enc_input)\n",
    "\n",
    "        current_decoder_input_token = torch.tensor([summary_vocab.stoi[SOS]]).to(device)\n",
    "        summary_tokens = []\n",
    "\n",
    "        for _ in range(max_summary_len):\n",
    "            predicted_token, enc_hidden, enc_cell = model.decoder_model(current_decoder_input_token, enc_hidden, enc_cell)\n",
    "            predicted_token_id = predicted_token.argmax(dim=1).item()\n",
    "            if predicted_token_id == summary_vocab.stoi[EOS]:\n",
    "                break\n",
    "            summary_tokens.append(predicted_token_id)\n",
    "            current_decoder_input_token = torch.tensor([predicted_token_id]).to(device)\n",
    "\n",
    "        summary_words = [summary_vocab.itos[token_id] for token_id in summary_tokens]\n",
    "        return ' '.join(summary_words)\n",
    "\n",
    "def summarize_text_beam_search(model, article, article_vocab, summary_vocab, device, max_summary_len=50, beam_width=3):\n",
    "    \"\"\"Beam search with repetition penalty and length normalization\"\"\"\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        enc_input = torch.tensor(article_vocab.encode(article)).unsqueeze(0).to(device)\n",
    "        enc_hidden, enc_cell = model.encoder_model(enc_input)\n",
    "        \n",
    "        # Initialize beams: (log_prob, tokens, hidden, cell, is_finished)\n",
    "        beams = [(0.0, [summary_vocab.stoi[SOS]], enc_hidden, enc_cell, False)]\n",
    "        finished_beams = []\n",
    "        \n",
    "        for step in range(max_summary_len):\n",
    "            new_beams = []\n",
    "            \n",
    "            for log_prob, tokens, h, c, is_finished in beams:\n",
    "                if is_finished:\n",
    "                    finished_beams.append((log_prob, tokens))\n",
    "                    continue\n",
    "                    \n",
    "                current_token = torch.tensor([tokens[-1]]).to(device)\n",
    "                logits, h_new, c_new = model.decoder_model(current_token, h, c)\n",
    "                log_probs = torch.log_softmax(logits, dim=1)[0]\n",
    "                \n",
    "                # Repetition penalty: penalize tokens that appear frequently in the sequence\n",
    "                for token_id in set(tokens[1:]):  # Skip SOS token\n",
    "                    count = tokens[1:].count(token_id)\n",
    "                    if count > 2:\n",
    "                        log_probs[token_id] -= 1.0 * (count - 1)  # Penalty increases with frequency\n",
    "                \n",
    "                # Block PAD token\n",
    "                log_probs[summary_vocab.stoi[PAD]] = float('-inf')\n",
    "                \n",
    "                # Get top-k candidates\n",
    "                top_k = torch.topk(log_probs, min(beam_width, log_probs.numel()), largest=True)\n",
    "                \n",
    "                for candidate_log_prob, candidate_id in zip(top_k.values, top_k.indices):\n",
    "                    if torch.isinf(candidate_log_prob):\n",
    "                        continue\n",
    "                    new_log_prob = log_prob + candidate_log_prob.item()\n",
    "                    new_tokens = tokens + [candidate_id.item()]\n",
    "                    is_eos = (candidate_id.item() == summary_vocab.stoi[EOS])\n",
    "                    \n",
    "                    new_beams.append((new_log_prob, new_tokens, h_new, c_new, is_eos))\n",
    "            \n",
    "            # Sort by normalized log probability (length penalty)\n",
    "            new_beams.sort(reverse=True, key=lambda x: x[0] / max(len(x[1]), 1) ** 0.7)\n",
    "            beams = new_beams[:beam_width]\n",
    "            \n",
    "            # Separate finished and unfinished beams\n",
    "            finished_beams.extend([b for b in beams if b[4]])\n",
    "            beams = [b for b in beams if not b[4]]\n",
    "            \n",
    "            if not beams:\n",
    "                break\n",
    "        \n",
    "        # Combine and sort all beams\n",
    "        all_beams = finished_beams + beams\n",
    "        all_beams.sort(reverse=True, key=lambda x: x[0] / max(len(x[1]), 1) ** 0.7)\n",
    "        \n",
    "        # Return best beam\n",
    "        if all_beams:\n",
    "            best_tokens = all_beams[0][1][1:]  # Remove SOS token\n",
    "            summary_words = [summary_vocab.itos[token_id] for token_id in best_tokens if token_id != summary_vocab.stoi[EOS]]\n",
    "            return ' '.join(summary_words)\n",
    "        return \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "775b4ba4",
   "metadata": {},
   "source": [
    "### üéØ Inference: Generating Summaries\n",
    "\n",
    "Now that the model is trained, let's use it to generate summaries!\n",
    "\n",
    "#### **Two Strategies:**\n",
    "\n",
    "---\n",
    "\n",
    "### 1Ô∏è‚É£ **Greedy Decoding** (`summarize_text`)\n",
    "\n",
    "**The Simple Approach:** Always pick the most likely word.\n",
    "\n",
    "#### **Step-by-Step Flow:**\n",
    "\n",
    "```\n",
    "Input Article: \"Scientists discovered a new planet orbiting a distant star...\"\n",
    "    ‚Üì\n",
    "Encode: encoder(article) ‚Üí h, c (context vectors)\n",
    "    ‚Üì\n",
    "Start with: <SOS> token\n",
    "\n",
    "Loop (max 50 times):\n",
    "  ‚îú‚îÄ Time 0: Input=<SOS>        ‚Üí Decoder ‚Üí Probabilities ‚Üí Pick \"scientists\" (highest)\n",
    "  ‚îú‚îÄ Time 1: Input=\"scientists\" ‚Üí Decoder ‚Üí Probabilities ‚Üí Pick \"discover\" (highest)\n",
    "  ‚îú‚îÄ Time 2: Input=\"discover\"   ‚Üí Decoder ‚Üí Probabilities ‚Üí Pick \"new\" (highest)\n",
    "  ‚îú‚îÄ Time 3: Input=\"new\"        ‚Üí Decoder ‚Üí Probabilities ‚Üí Pick \"planet\" (highest)\n",
    "  ‚îî‚îÄ Time 4: Input=\"planet\"     ‚Üí Decoder ‚Üí Probabilities ‚Üí Pick <EOS> (stop!)\n",
    "\n",
    "Output: \"scientists discover new planet\"\n",
    "```\n",
    "\n",
    "**Key Difference from Training:**\n",
    "- **Training**: Uses teacher forcing (real target words)\n",
    "- **Inference**: Uses its own predictions (no ground truth available!)\n",
    "\n",
    "---\n",
    "\n",
    "### 2Ô∏è‚É£ **Beam Search** (`summarize_text_beam_search`)\n",
    "\n",
    "**The Smart Approach:** Explore multiple possibilities simultaneously.\n",
    "\n",
    "#### **How Beam Search Works:**\n",
    "\n",
    "Instead of keeping only the best word, we keep the **top-K (beam_width=3) sequences**.\n",
    "\n",
    "```\n",
    "Start: <SOS>\n",
    "    ‚Üì\n",
    "Time 0: Generate 3 best options\n",
    "  Beam 1: <SOS> \"scientists\" (prob=0.8)\n",
    "  Beam 2: <SOS> \"new\"        (prob=0.6)\n",
    "  Beam 3: <SOS> \"researchers\" (prob=0.5)\n",
    "    ‚Üì\n",
    "Time 1: From EACH beam, generate 3 options (9 total), keep best 3\n",
    "  Beam 1: <SOS> \"scientists\" \"discover\" (prob=0.8*0.9=0.72)\n",
    "  Beam 2: <SOS> \"new\" \"planet\"          (prob=0.6*0.8=0.48)\n",
    "  Beam 3: <SOS> \"scientists\" \"find\"     (prob=0.8*0.7=0.56)\n",
    "    ‚Üì\n",
    "Time 2: Continue... keep best 3 paths\n",
    "    ‚Üì\n",
    "...\n",
    "    ‚Üì\n",
    "Final: Pick the sequence with highest probability\n",
    "```\n",
    "\n",
    "**Enhancements in the Code:**\n",
    "\n",
    "1. **Repetition Penalty:**\n",
    "   ```python\n",
    "   if count > 2:\n",
    "       log_probs[token_id] -= 1.0 * (count - 1)\n",
    "   ```\n",
    "   Penalizes words that appear too often (avoid \"the the the...\")\n",
    "\n",
    "2. **Length Normalization:**\n",
    "   ```python\n",
    "   new_log_prob / max(len(new_tokens), 1) ** 0.7\n",
    "   ```\n",
    "   Prevents bias toward shorter sequences\n",
    "\n",
    "3. **PAD Token Blocking:**\n",
    "   ```python\n",
    "   log_probs[summary_vocab.stoi[PAD]] = float('-inf')\n",
    "   ```\n",
    "   Never predict padding tokens\n",
    "\n",
    "**Greedy vs Beam Search:**\n",
    "- **Greedy**: Fast, but can miss better sequences\n",
    "- **Beam Search**: Slower, but explores alternatives and often produces better summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fe0703c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Greedy Decoding:\")\n",
    "print(summarize_text(sequence_to_sequence_model, df.iloc[0][\"news\"], article_vocab, summary_vocab, device))\n",
    "\n",
    "print(\"\\nBeam Search Decoding (beam_width=3):\")\n",
    "print(summarize_text_beam_search(sequence_to_sequence_model, df.iloc[0][\"news\"], article_vocab, summary_vocab, device, beam_width=3))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
