{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "389650c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence #</th>\n",
       "      <th>Word</th>\n",
       "      <th>POS</th>\n",
       "      <th>Tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>Thousands</td>\n",
       "      <td>NNS</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>of</td>\n",
       "      <td>IN</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>demonstrators</td>\n",
       "      <td>NNS</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>have</td>\n",
       "      <td>VBP</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>marched</td>\n",
       "      <td>VBN</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NaN</td>\n",
       "      <td>through</td>\n",
       "      <td>IN</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>NaN</td>\n",
       "      <td>London</td>\n",
       "      <td>NNP</td>\n",
       "      <td>B-geo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>NaN</td>\n",
       "      <td>to</td>\n",
       "      <td>TO</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>NaN</td>\n",
       "      <td>protest</td>\n",
       "      <td>VB</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>NaN</td>\n",
       "      <td>the</td>\n",
       "      <td>DT</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Sentence #           Word  POS    Tag\n",
       "0  Sentence: 1      Thousands  NNS      O\n",
       "1          NaN             of   IN      O\n",
       "2          NaN  demonstrators  NNS      O\n",
       "3          NaN           have  VBP      O\n",
       "4          NaN        marched  VBN      O\n",
       "5          NaN        through   IN      O\n",
       "6          NaN         London  NNP  B-geo\n",
       "7          NaN             to   TO      O\n",
       "8          NaN        protest   VB      O\n",
       "9          NaN            the   DT      O"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df=pd.read_csv(\"data/recognition_data.csv\",encoding='utf-8',sep=',',encoding_errors='ignore')\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d02bbf7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tag\n",
       "O        887908\n",
       "B-geo     37644\n",
       "B-tim     20333\n",
       "B-org     20143\n",
       "I-per     17251\n",
       "B-per     16990\n",
       "I-org     16784\n",
       "B-gpe     15870\n",
       "I-geo      7414\n",
       "I-tim      6528\n",
       "B-art       402\n",
       "B-eve       308\n",
       "I-art       297\n",
       "I-eve       253\n",
       "B-nat       201\n",
       "I-gpe       198\n",
       "I-nat        51\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"Tag\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3965c86",
   "metadata": {},
   "source": [
    "**Label Explanation**: \n",
    "- `O` = Outside (not an entity), \n",
    "- `B-*` = Beginning of entity, \n",
    "- `I-*` = Inside/continuation of entity, where `*` represents the entity type: \n",
    "- `geo` (geopolitical), \n",
    "- `tim` (time), \n",
    "- `org` (organization), \n",
    "- `per` (person), \n",
    "- `gpe` (geopolitical entity), \n",
    "- `art` (artifact), \n",
    "- `eve` (event), \n",
    "- `nat` (natural)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "10e32759",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1048575, 4)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d5b1203d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0          O\n",
       "1          O\n",
       "2          O\n",
       "3          O\n",
       "4          O\n",
       "          ..\n",
       "1048570    O\n",
       "1048571    O\n",
       "1048572    O\n",
       "1048573    O\n",
       "1048574    O\n",
       "Name: Tag, Length: 1048575, dtype: object"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"Tag\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca4f59c5",
   "metadata": {},
   "source": [
    "# Target:\n",
    "sentences = [\n",
    "    [\"Thousands\", \"of\", \"demonstrators\", \"have\", ...],\n",
    "    [\"Families\", \"of\", \"soldiers\", \"killed\", ...]\n",
    "]\n",
    "\n",
    "labels = [\n",
    "    [\"O\", \"O\", \"O\", \"O\", \"B-geo\", ...],\n",
    "    [\"O\", \"O\", \"O\", \"O\", ...]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e860de85",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LENOVO\\AppData\\Local\\Temp\\ipykernel_19352\\2406357841.py:1: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[\"Sentence #\"].fillna(method=\"ffill\",inplace=True)\n",
      "C:\\Users\\LENOVO\\AppData\\Local\\Temp\\ipykernel_19352\\2406357841.py:1: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  df[\"Sentence #\"].fillna(method=\"ffill\",inplace=True)\n"
     ]
    }
   ],
   "source": [
    "df[\"Sentence #\"].fillna(method=\"ffill\",inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "61f476e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([list(['Thousands', 'of', 'demonstrators', 'have', 'marched', 'through', 'London', 'to', 'protest', 'the', 'war', 'in', 'Iraq', 'and', 'demand', 'the', 'withdrawal', 'of', 'British', 'troops', 'from', 'that', 'country', '.']),\n",
       "       list(['Iranian', 'officials', 'say', 'they', 'expect', 'to', 'get', 'access', 'to', 'sealed', 'sensitive', 'parts', 'of', 'the', 'plant', 'Wednesday', ',', 'after', 'an', 'IAEA', 'surveillance', 'system', 'begins', 'functioning', '.']),\n",
       "       list(['Helicopter', 'gunships', 'Saturday', 'pounded', 'militant', 'hideouts', 'in', 'the', 'Orakzai', 'tribal', 'region', ',', 'where', 'many', 'Taliban', 'militants', 'are', 'believed', 'to', 'have', 'fled', 'to', 'avoid', 'an', 'earlier', 'military', 'offensive', 'in', 'nearby', 'South', 'Waziristan', '.']),\n",
       "       list(['They', 'left', 'after', 'a', 'tense', 'hour-long', 'standoff', 'with', 'riot', 'police', '.'])],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby(\"Sentence #\")[\"Word\"].apply(list).values[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "67b3fd15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([['Thousands',\n",
       "   'of',\n",
       "   'demonstrators',\n",
       "   'have',\n",
       "   'marched',\n",
       "   'through',\n",
       "   'London',\n",
       "   'to',\n",
       "   'protest',\n",
       "   'the',\n",
       "   'war',\n",
       "   'in',\n",
       "   'Iraq',\n",
       "   'and',\n",
       "   'demand',\n",
       "   'the',\n",
       "   'withdrawal',\n",
       "   'of',\n",
       "   'British',\n",
       "   'troops',\n",
       "   'from',\n",
       "   'that',\n",
       "   'country',\n",
       "   '.'],\n",
       "  ['Iranian',\n",
       "   'officials',\n",
       "   'say',\n",
       "   'they',\n",
       "   'expect',\n",
       "   'to',\n",
       "   'get',\n",
       "   'access',\n",
       "   'to',\n",
       "   'sealed',\n",
       "   'sensitive',\n",
       "   'parts',\n",
       "   'of',\n",
       "   'the',\n",
       "   'plant',\n",
       "   'Wednesday',\n",
       "   ',',\n",
       "   'after',\n",
       "   'an',\n",
       "   'IAEA',\n",
       "   'surveillance',\n",
       "   'system',\n",
       "   'begins',\n",
       "   'functioning',\n",
       "   '.']],\n",
       " [['O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'B-geo',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'B-geo',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'B-gpe',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O'],\n",
       "  ['B-gpe',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'B-tim',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'B-org',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O']])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences=df.groupby(\"Sentence #\")[\"Word\"].apply(list).values.tolist()\n",
    "labels=df.groupby(\"Sentence #\")[\"Tag\"].apply(list).values.tolist()\n",
    "\n",
    "sentences[:2], labels[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "07221ddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "word2idx = {\"<PAD>\": 0, \"<UNK>\": 1}\n",
    "tag2idx = {\"<PAD>\": 0}\n",
    "\n",
    "for sent in sentences:\n",
    "    for w in sent:\n",
    "        if w not in word2idx:\n",
    "            word2idx[w] = len(word2idx)\n",
    "\n",
    "for tag_seq in labels:\n",
    "    for t in tag_seq:\n",
    "        if t not in tag2idx:\n",
    "            tag2idx[t] = len(tag2idx)\n",
    "\n",
    "idx2tag = {v: k for k, v in tag2idx.items()}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c3fdc368",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode(sentences, labels, word2idx, tag2idx):\n",
    "    X, y = [], []\n",
    "    for sent, labels in zip(sentences, labels):\n",
    "        X.append([word2idx.get(word,word2idx[\"<UNK>\"]) for word in sent]) #Return the value for key if key is in the dictionary, else default.\n",
    "        y.append([tag2idx[t] for t in labels])\n",
    "    return X, y\n",
    "\n",
    "X, y = encode(sentences, labels, word2idx, tag2idx)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "41109b39",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "MAX_LEN = max(len(s) for s in X)\n",
    "\n",
    "def pad(seq, max_len):\n",
    "    return seq + [0] * (max_len - len(seq))\n",
    "\n",
    "X = torch.tensor([pad(s, MAX_LEN) for s in X])\n",
    "y = torch.tensor([pad(s, MAX_LEN) for s in y])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "708f4351",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class NERModel(nn.Module):\n",
    "    def __init__(self, vocab_size, target_size, embedding_dim, hidden_dim, num_layers):\n",
    "        super(NERModel, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx=0)\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, num_layers, batch_first=True, bidirectional=True)\n",
    "        self.fc = nn.Linear(hidden_dim * 2, target_size) # since bidirectional we multiply by 2 \n",
    "        \n",
    "    def forward(self, x):\n",
    "        embed = self.embedding(x)\n",
    "        lstm_output, _ = self.lstm(embed)\n",
    "        x = self.fc(lstm_output)\n",
    "        return x\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5d73e2ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "NERModel(\n",
       "  (embedding): Embedding(35171, 128, padding_idx=0)\n",
       "  (lstm): LSTM(128, 256, num_layers=2, batch_first=True, bidirectional=True)\n",
       "  (fc): Linear(in_features=512, out_features=18, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "model = NERModel(vocab_size=len(word2idx), target_size=len(tag2idx), embedding_dim=128, hidden_dim=256, num_layers=2)\n",
    "model = model.to(device)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fc111dcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss(ignore_index=0)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66c9a93c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "EPOCHS = 10\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for i in tqdm(range(len(X))):\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        x_batch = X[i].unsqueeze(0).to(device)  # Move to GPU\n",
    "        y_batch = y[i].to(device)  # Move to GPU\n",
    "        outputs = model(x_batch)  # Add batch dimension as lstm requires 3D input\n",
    "        loss = loss_fn(outputs.view(-1, len(tag2idx)), y_batch.view(-1)) # Reshape for loss computation\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c1ed8068",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def predict(sentence):\n",
    "    # Load the model properly\n",
    "    loaded_model = NERModel(vocab_size=len(word2idx), target_size=len(tag2idx), embedding_dim=128, hidden_dim=256, num_layers=2)\n",
    "    loaded_model.load_state_dict(torch.load(\"ner_model.pth\", map_location=torch.device('cpu')))\n",
    "    loaded_model = loaded_model.to(device)\n",
    "    loaded_model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        tokens = sentence.split()\n",
    "        encoded = [word2idx.get(w, word2idx[\"<UNK>\"]) for w in tokens]\n",
    "        padded = encoded + [0] * (MAX_LEN - len(encoded))\n",
    "        x = torch.tensor([padded]).to(device)\n",
    "\n",
    "        logits = loaded_model(x)\n",
    "        preds = torch.argmax(logits, dim=-1)[0]\n",
    "\n",
    "        return [(w, idx2tag[p.item()]) for w, p in zip(tokens, preds)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c51e516",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(model.state_dict(), \"ner_model.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9be94cde",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy import displacy\n",
    "from IPython.display import HTML\n",
    "\n",
    "def visualize_predictions(sentence):\n",
    "    \"\"\"Visualize BiLSTM NER predictions using spaCy displacy style\"\"\"\n",
    "    predictions = predict(sentence)\n",
    "    \n",
    "    # Create spaCy-style doc format\n",
    "    tokens = sentence.split()\n",
    "    entities = []\n",
    "    char_pos = 0\n",
    "    \n",
    "    for i, (token, tag) in enumerate(predictions):\n",
    "        if tag != 'O':  # Only include actual entities\n",
    "            start = sentence.find(token, char_pos)\n",
    "            end = start + len(token)\n",
    "            entities.append({\n",
    "                'start': start,\n",
    "                'end': end,\n",
    "                'label': tag\n",
    "            })\n",
    "            char_pos = end\n",
    "    \n",
    "    # Create doc object for displacy\n",
    "    doc_dict = {\n",
    "        'text': sentence,\n",
    "        'ents': entities,\n",
    "        'title': None\n",
    "    }\n",
    "    \n",
    "    # Force jupyter=False to avoid IPython display import issues\n",
    "    html = displacy.render(doc_dict, style='ent', manual=True, jupyter=False)\n",
    "    return HTML(html)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e9340d56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">The Airline industry is facing challenges in \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    2023.\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">B-art</span>\n",
       "</mark>\n",
       " This affects companies like \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Delta\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">B-per</span>\n",
       "</mark>\n",
       " and \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    American\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">B-gpe</span>\n",
       "</mark>\n",
       " \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Airlines.\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">I-org</span>\n",
       "</mark>\n",
       "</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "visualize_predictions(\"The Airline industry is facing challenges in 2023. This affects companies like Delta and American Airlines.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e348a4f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "511e8670",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
