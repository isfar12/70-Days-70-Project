{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43f955cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import T5Tokenizer, T5ForConditionalGeneration, T5Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "01897cec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install sentencepiece"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5f4cdf6",
   "metadata": {},
   "source": [
    "# Option 1: Using T5 Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ee7e5cb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#initialize the model and tokenizer\n",
    "model_name = 't5-small'\n",
    "tokenizer = T5Tokenizer.from_pretrained(model_name)\n",
    "config = T5Config.from_pretrained(model_name)\n",
    "model = T5ForConditionalGeneration.from_pretrained(model_name, config=config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e006bb5f",
   "metadata": {},
   "source": [
    "T5 models expect the input text to be prefixed with a task-specific prompt, such as \"summarize: \" for summarization tasks. This helps the model understand what kind of output is expected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "721fbd83",
   "metadata": {},
   "outputs": [],
   "source": [
    "text=\"\"\"We all know that OpenAI actually started the trend of AI tools after releasing ChatGPT.\n",
    "\n",
    "After that, we saw everyone shift to AI. Developers and big companies began building AI tools, and even individuals started learning about artificial intelligence.\n",
    "\n",
    "Thanks to that, we have tons of popular AI tools like RunwayML, Lovable, Claude, Gemini, Perplexity, Cursor, Stitch, NotebookLM, Leonardo AI, Framer AI, and the list goes on.\n",
    "\n",
    "That's not all. Every day, tons of new AI tools are launched, which makes it difficult for people to find the best ones for their needs.\n",
    "\n",
    "That's why I spend a lot of time testing some of the best new AI tools and write a couple of posts every month to share the ones that truly stand out.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "16fddf93",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import html\n",
    "# modified with GPT for best practices\n",
    "def clean_text(text):\n",
    "    text = html.unescape(text)\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'<.*?>', ' ', text)             # remove HTML\n",
    "    text = re.sub(r'http\\S+|www\\.\\S+', ' ', text)  # remove URLs\n",
    "    text = re.sub(r'\\S+@\\S+', ' ', text)           # remove emails\n",
    "    text = re.sub(r\"(.)\\1{2,}\", r\"\\1\\1\", text)     # soooo -> soo\n",
    "\n",
    "    # keep ! and ? (sentiment)\n",
    "    text = re.sub(r'[^a-z!? ]', ' ', text)\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "60dffac2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "127"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_text=clean_text(text).split()\n",
    "len(cleaned_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "af12d5dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[21603,    10,    62,    66,   214,    24,   539,     9,    23,   700,\n",
      "           708,     8,  4166,    13,     3,     9,    23,  1339,   227,     3,\n",
      "         16306,  3582,   122,   102,    17,   227,    24,    62,  1509,   921,\n",
      "          4108,    12,     3,     9,    23,  5564,    11,   600,   688,  1553,\n",
      "           740,     3,     9,    23,  1339,    11,   237,  1742,   708,  1036,\n",
      "            81,  7353,  6123,  2049,    12,    24,    62,    43,  8760,    13,\n",
      "          1012,     3,     9,    23,  1339,   114, 22750,    51,    40,     3,\n",
      "          5850,   179,     3,    75, 12513,    15,   873,  7619,   399,  9247,\n",
      "           485,  8385,   127, 12261, 16638,    40,    51,    90,   106,   986,\n",
      "            32,     3,     9,    23,  2835,    52,     3,     9,    23,    11,\n",
      "             8,   570,  1550,    30,    24,     3,     7,    59,    66,   334,\n",
      "           239,  8760,    13,   126,     3,     9,    23,  1339,    33,  3759,\n",
      "            84,   656,    34,  1256,    21,   151,    12,   253,     8,   200,\n",
      "          2102,    21,    70,   523,    24,     3,     7,   572,     3,    23,\n",
      "          1492,     3,     9,   418,    13,    97,  2505,   128,    13,     8,\n",
      "           200,   126,     3,     9,    23,  1339,    11,  1431,     3,     9,\n",
      "          1158,    13,  3489,   334,   847,    12,   698,     8,  2102,    24,\n",
      "          1892,  1518,    91,     1]])\n"
     ]
    }
   ],
   "source": [
    "tokenized_text=tokenizer.encode(\"summarize: \" + clean_text(text), return_tensors=\"pt\", max_length=512, truncation=True)\n",
    "print(tokenized_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0ef34c0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary:\n",
      "openai has tons of popular ai tools like runwayml lovable claude gemini perplexity cursor stitch notebooklm leonardo ai framer ai. the list goes on that s not all every day tons of new ai tools are launched which makes it difficult for people to find the best ones for their needs.\n",
      "51\n"
     ]
    }
   ],
   "source": [
    "summary_ids=model.generate(tokenized_text, max_length=150, min_length=40, length_penalty=2.0, num_beams=4, early_stopping=True)\n",
    "summary=tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
    "\n",
    "print(\"Summary:\")\n",
    "print(summary)\n",
    "print(len(summary.split()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1860326",
   "metadata": {},
   "source": [
    "# Option 2 : Using Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75e531e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\LENOVO\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a03e861a5a44935ab10ebc0044dda77",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/1.63G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "414b5b984514410e9e7eeda0c349fc4a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/363 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ddca32e9b54446f08d6adba30d852090",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a9a3c931e98405fb8e88524d665bac6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2339fe65b86a484b9d9848b51cc44757",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'summary_text': \"Every day, tons of new AI tools are launched, which makes it difficult for people to find the best ones for their needs. That's why I spend a lot of time testing some of the best newAI tools and write a couple of posts every month to share the ones that truly stand out.\"}]\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "summarizer = pipeline(\"summarization\", model=\"facebook/bart-large-cnn\")\n",
    "summary = summarizer(text, max_length=130, min_length=30)\n",
    "\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0b23635",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
