{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "982d3595",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment\n",
       "0  One of the other reviewers has mentioned that ...  positive\n",
       "1  A wonderful little production. <br /><br />The...  positive\n",
       "2  I thought this was a wonderful way to spend ti...  positive\n",
       "3  Basically there's a family where a little boy ...  negative\n",
       "4  Petter Mattei's \"Love in the Time of Money\" is...  positive"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df=pd.read_csv(\"data/IMDB Dataset.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e3cc7dda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "One of the other reviewers has mentioned that after watching just 1 Oz episode you'll be hooked. They are right, as this is exactly what happened with me.<br /><br />The first thing that struck me about Oz was its brutality and unflinching scenes of violence, which set in right from the word GO. Trust me, this is not a show for the faint hearted or timid. This show pulls no punches with regards to drugs, sex or violence. Its is hardcore, in the classic use of the word.<br /><br />It is called OZ as that is the nickname given to the Oswald Maximum Security State Penitentary. It focuses mainly on Emerald City, an experimental section of the prison where all the cells have glass fronts and face inwards, so privacy is not high on the agenda. Em City is home to many..Aryans, Muslims, gangstas, Latinos, Christians, Italians, Irish and more....so scuffles, death stares, dodgy dealings and shady agreements are never far away.<br /><br />I would say the main appeal of the show is due to the fact that it goes where other shows wouldn't dare. Forget pretty pictures painted for mainstream audiences, forget charm, forget romance...OZ doesn't mess around. The first episode I ever saw struck me as so nasty it was surreal, I couldn't say I was ready for it, but as I watched more, I developed a taste for Oz, and got accustomed to the high levels of graphic violence. Not just violence, but injustice (crooked guards who'll be sold out for a nickel, inmates who'll kill on order and get away with it, well mannered, middle class inmates being turned into prison bitches due to their lack of street skills or prison experience) Watching Oz, you may become comfortable with what is uncomfortable viewing....thats if you can get in touch with your darker side.\n"
     ]
    }
   ],
   "source": [
    "print(df.review[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "68354428",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['positive' 'negative']\n"
     ]
    }
   ],
   "source": [
    "classes = df['sentiment'].unique()\n",
    "print(classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e830b2d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y= df['review'],df['sentiment']\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "46e814b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import html\n",
    "# modified with GPT for best practices\n",
    "def clean_text(text):\n",
    "    text = html.unescape(text)\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'<.*?>', ' ', text)             # remove HTML\n",
    "    text = re.sub(r'http\\S+|www\\.\\S+', ' ', text)  # remove URLs\n",
    "    text = re.sub(r'\\S+@\\S+', ' ', text)           # remove emails\n",
    "    text = re.sub(r\"(.)\\1{2,}\", r\"\\1\\1\", text)     # soooo -> soo\n",
    "\n",
    "    # keep ! and ? (sentiment)\n",
    "    text = re.sub(r'[^a-z!? ]', ' ', text)\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4b70f53",
   "metadata": {},
   "source": [
    "Ref : https://www.kaggle.com/code/arunmohan003/sentiment-analysis-using-lstm-pytorch\n",
    "\n",
    "and Copilot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb8b68cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from gensim.parsing.preprocessing import preprocess_string\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "def tokenize(x_train, y_train, x_val, y_val, max_len=100):\n",
    "\n",
    "    word_list = []\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    \n",
    "    # Build vocabulary from training data\n",
    "    print(\"Building vocabulary...\")\n",
    "    for sent in x_train:\n",
    "        for word in sent.lower().split():\n",
    "            processed = preprocess_string(word)\n",
    "            if processed:  # Check if preprocess_string returned anything\n",
    "                word = processed[0]\n",
    "                if word not in stop_words and word != '':\n",
    "                    word_list.append(word)\n",
    "    \n",
    "    # Create vocabulary dictionary\n",
    "    corpus = Counter(word_list)\n",
    "    corpus_ = sorted(corpus, key=corpus.get, reverse=True)[:1000]\n",
    "    onehot_dict = {w: i+1 for i, w in enumerate(corpus_)}  # Start from 1, 0 is for padding\n",
    "    \n",
    "    print(f\"Vocabulary size: {len(onehot_dict)}\")\n",
    "    \n",
    "    # Tokenize sequences\n",
    "    print(\"Tokenizing training data...\")\n",
    "    final_list_train = []\n",
    "    for sent in x_train:\n",
    "        tokens = []\n",
    "        for word in sent.lower().split():\n",
    "            processed = preprocess_string(word)\n",
    "            if processed and processed[0] in onehot_dict:\n",
    "                tokens.append(onehot_dict[processed[0]])\n",
    "        final_list_train.append(tokens)\n",
    "    \n",
    "    print(\"Tokenizing validation data...\")\n",
    "    final_list_test = []\n",
    "    for sent in x_val:\n",
    "        tokens = []\n",
    "        for word in sent.lower().split():\n",
    "            processed = preprocess_string(word)\n",
    "            if processed and processed[0] in onehot_dict:\n",
    "                tokens.append(onehot_dict[processed[0]])\n",
    "        final_list_test.append(tokens)\n",
    "    \n",
    "    # Pad sequences to same length\n",
    "    print(f\"Padding sequences to max length: {max_len}\")\n",
    "    padded_train = pad_sequences(final_list_train, maxlen=max_len, padding='post', truncating='post')\n",
    "    padded_test = pad_sequences(final_list_test, maxlen=max_len, padding='post', truncating='post')\n",
    "    \n",
    "    # Encode labels\n",
    "    encoded_train = np.array([1 if label == 'positive' else 0 for label in y_train])\n",
    "    encoded_test = np.array([1 if label == 'positive' else 0 for label in y_val])\n",
    "    \n",
    "    print(f\"Training data shape: {padded_train.shape}\")\n",
    "    print(f\"Validation data shape: {padded_test.shape}\")\n",
    "    \n",
    "    return padded_train, encoded_train, padded_test, encoded_test, onehot_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a0e8f2f",
   "metadata": {},
   "source": [
    "### GPT SAID\n",
    "Perfect! The tokenizer is now working correctly. I've created a robust tokenizer that:\n",
    "\n",
    "Properly handles preprocess_string() - Checks if it returns data and extracts the first element\n",
    "Builds a vocabulary from the 1000 most common words in training data\n",
    "Converts text to sequences of integer indices\n",
    "Pads sequences to a uniform length (100 tokens) using pad_sequences from Keras\n",
    "Encodes labels as binary values (1 for positive, 0 for negative)\n",
    "Returns proper numpy arrays with consistent shapes\n",
    "The output shows:\n",
    "\n",
    "Vocabulary size: 1000 words\n",
    "Training data shape: (40000, 100) - 40,000 samples, 100 tokens each\n",
    "Validation data shape: (10000, 100) - 10,000 samples, 100 tokens each\n",
    "You can now proceed with building your sentiment analysis model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b9b2d982",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import nltk\n",
    "# nltk.download('stopwords')\n",
    "# nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "087d9742",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building vocabulary...\n",
      "Vocabulary size: 1000\n",
      "Tokenizing training data...\n",
      "Tokenizing validation data...\n",
      "Padding sequences to max length: 100\n",
      "Training data shape: (40000, 100)\n",
      "Validation data shape: (10000, 100)\n"
     ]
    }
   ],
   "source": [
    "x_train,y_train,x_test,y_test,vocab = tokenize(X_train,y_train,X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9245a17c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Length of vocabulary is {len(vocab)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ddf383ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def padding_(sentences, seq_len):\n",
    "    features = np.zeros((len(sentences), seq_len),dtype=int)\n",
    "    for ii, review in enumerate(sentences):\n",
    "        if len(review) != 0:\n",
    "            features[ii, -len(review):] = np.array(review)[:seq_len]\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "21c79c24",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_pad = padding_(x_train,500)\n",
    "x_test_pad = padding_(x_test,500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee60579c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import torch\n",
    "\n",
    "train_data = TensorDataset(torch.from_numpy(x_train_pad), torch.from_numpy(y_train))\n",
    "valid_data = TensorDataset(torch.from_numpy(x_test_pad), torch.from_numpy(y_test))\n",
    "\n",
    "batch_size = 50\n",
    "\n",
    "train_loader = DataLoader(train_data, shuffle=True, batch_size=batch_size)\n",
    "valid_loader = DataLoader(valid_data, shuffle=True, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3adbd3c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample input size:  torch.Size([50, 500])\n",
      "Sample input: \n",
      " tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0]])\n",
      "Sample input: \n",
      " tensor([1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1,\n",
      "        1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0,\n",
      "        0, 1])\n"
     ]
    }
   ],
   "source": [
    "dataiter = iter(train_loader)\n",
    "sample_x, sample_y = next(dataiter)\n",
    "\n",
    "print('Sample input size: ', sample_x.size()) # batch_size, seq_length\n",
    "print('Sample input: \\n', sample_x)\n",
    "print('Sample input: \\n', sample_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d47458c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class SentimentLSTM(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim, num_layers=2, bidirectional=False, dropout=.3): \n",
    "        super(SentimentLSTM, self).__init__()\n",
    "        # input =(batch X seq_len)\n",
    "        self.embedding = nn.Embedding(num_embeddings=vocab_size, embedding_dim=embedding_dim, padding_idx=0) \n",
    "        # output = (batch X seq_len X embedding_dim) each seq token is represented by embedding_dim vector\n",
    "        self.lstm = nn.LSTM(input_size=embedding_dim, hidden_size=hidden_dim,\n",
    "                           num_layers=num_layers, bidirectional=bidirectional, dropout=dropout, batch_first=True) \n",
    "        # output = (batch X seq_len X hidden_dim * num_directions) if bidirectional then num_directions=2 else 1\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        # output = (batch X hidden_dim * num_directions) flattening\n",
    "        self.fc = nn.Linear(in_features=hidden_dim*(2 if bidirectional else 1), out_features=1)\n",
    "        # No sigmoid here - BCEWithLogitsLoss applies it internally\n",
    "        \n",
    "    def forward(self, x):\n",
    "        embedded = self.embedding(x)  # (B X seq_len X embedding_dim)\n",
    "        lstm_out, (hidden_state, cell_state) = self.lstm(embedded)  # lstm_out: (B X seq_len X H*num_directions)\n",
    "        # hidden_state: (num_layers * num_directions, B, H)\n",
    "\n",
    "        if self.lstm.bidirectional:\n",
    "            h_last = torch.cat((hidden_state[-2], hidden_state[-1]), dim=1)  # (B, 2H)\n",
    "        else:\n",
    "            h_last = hidden_state[-1]  # (B, H)\n",
    "            \n",
    "        out = self.dropout(h_last)\n",
    "        out = self.fc(out)  # (B, 1) - raw logits, no sigmoid\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "1f7e9c4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SentimentLSTM(\n",
      "  (embedding): Embedding(1001, 128, padding_idx=0)\n",
      "  (lstm): LSTM(128, 256, num_layers=2, batch_first=True, dropout=0.3, bidirectional=True)\n",
      "  (dropout): Dropout(p=0.3, inplace=False)\n",
      "  (fc): Linear(in_features=512, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model=SentimentLSTM(vocab_size=len(vocab)+1,embedding_dim=128,hidden_dim=256,bidirectional=True,num_layers=2,dropout=0.3) # add 1 for padding index\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "bfa44328",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 1])\n"
     ]
    }
   ],
   "source": [
    "x = torch.randint(low=0, high=len(vocab), size=(32, 200))  # fake batch\n",
    "with torch.no_grad():\n",
    "    y = model(x)\n",
    "print(y.shape)  # output= torch.Size([32, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "5ddfe0e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = torch.nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "epochs = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3affcb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/5:   1%|          | 6/800 [06:19<13:38:55, 61.88s/it]"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    \n",
    "    for inputs, labels in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{epochs}\"):\n",
    "        inputs, labels = inputs.to(device), labels.to(device).float()\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        outputs = model(inputs).squeeze()  # squeeze to match labels shape\n",
    "        \n",
    "        loss = criterion(outputs, labels)  # calculate loss\n",
    "        loss.backward()  # backpropagation\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "    \n",
    "    avg_loss = total_loss / len(train_loader)\n",
    "    print(f\"Epoch {epoch+1}/{epochs}, Training Loss: {avg_loss:.4f}\")\n",
    "    \n",
    "    # Validation\n",
    "    model.eval()\n",
    "    total_val_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in valid_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device).float()\n",
    "            \n",
    "            outputs = model(inputs).squeeze()  # raw logits\n",
    "            \n",
    "            val_loss = criterion(outputs, labels)\n",
    "            total_val_loss += val_loss.item()\n",
    "            \n",
    "            # Apply sigmoid for prediction since model outputs raw logits\n",
    "            predicted = (torch.sigmoid(outputs) >= 0.5).float()\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "            \n",
    "    avg_val_loss = total_val_loss / len(valid_loader)\n",
    "    val_accuracy = correct / total\n",
    "    print(f\"Epoch {epoch+1}/{epochs}, Validation Loss: {avg_val_loss:.4f}, Validation Accuracy: {val_accuracy:.4f}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24cbc613",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_sentiment(model, sentence, vocab, seq_len=500):\n",
    "    model.eval()\n",
    "    cleaned = clean_text(sentence)\n",
    "    tokens = []\n",
    "    for word in cleaned.split():\n",
    "        processed = preprocess_string(word)\n",
    "        if processed and processed[0] in vocab:\n",
    "            tokens.append(vocab[processed[0]])\n",
    "    padded_seq = padding_([tokens], seq_len)\n",
    "    input_tensor = torch.from_numpy(padded_seq).to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        output = model(input_tensor).squeeze()\n",
    "        prob = torch.sigmoid(output).item()\n",
    "        \n",
    "    sentiment = 'positive' if prob >= 0.5 else 'negative'\n",
    "    return sentiment, prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d6583fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(predict_sentiment(model, \"I really loved this movie! It was fantastic and thrilling.\", vocab))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
